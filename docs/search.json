[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "An Introduction to NFL Analytics with R",
    "section": "",
    "text": "1 Introduction\nOn April 27, 2020, Ben Baldwin hit send on a Tweet that announced the birth of nflfastR, an R package designed to scrape NFL play-by-play data, allowing the end-user to access it at speeds quicker than similar predecessors (hence the name).\nThanks to the work of multiple people (@mrcaseB, @benbbaldwin, @TanHo, @LeeSharpeNFL, and @thomas_mock … to just name a few), the process of getting started with advanced analytics using NFL data is now easier than ever.\nThat said, and without getting too far into the weeds of the history behind it all, the above-mentioned people are responsible in some shape or form for the current status of the nflverse, which is a superb collection of data and R-based packages that allows anybody the ability to access deeply robust NFL data as far back as the 1999 season.\nThe nflverse as we know it today was initially birthed from the nflscrapR project, which was started by the Carnegie Mellon University student and profess duo of Maksim Horowitz and Sam Ventura. After Horowitz graduated - and got hired by the Atlanta Hawks - the nflscrapR package was taken over by fellow CMU student Ron Yorko (who would go on to receive his Ph.D. from the Statistics and Data Science program). The trio’s work on nflscrapR ultimately led to a peer-reviewed paper titled “nflWAR: A Reproducible Method for Offensive Player Evaluation in Football.” Ultimately, the nflscrapR project came to an end when the specific .json feed used to gather NFL data changed. At this point, Ben Baldwin and Sebastian Carl had already built upon the nflscrapR project’s foundations to create nflfastR. Ron officially marked the end of the nflscrapR era and the beginning of the nflfastR era with a tweet on September 14, 2020:1\nAs a reply to his first tweet about the nflfastR project, Ben explained that he created the original function to scrape NFL data for the creation of his NFL analytics website. Thankfully, he and Seb did not keep the creation to themselves and released nflfastR to the public. Because of the “open source” nature of R and R packages, a laundry list of companion packages quickly developed alongside nflfastR. The original nflfastR package is now part of the larger nflverse of packages that drive the NFL analytics community on Twitter and beyond.\nThe creation of the nflverse allowed for anybody interested in NFL analytics to easily access data, manipulate it to their liking, and release their visualizations and/or metrics to the wider public. In fact, it is now a regular occurrence for somebody to advance their R programming ability because of the nflverse and then go on to win the Big Data Bowl. As of the 2022 version of the Big Data Bowl, over “30 participants have been hired to work in data and analytics roles in sports, including 22 that were hired in football” (“Big Data Bowl: The Annual Analytics Contest Explores Statistical Innovations in Football,” n.d.). Most recently, the Chargers hired 2020 participate Alex Stern and the Chiefs hired Marc Richards, a member of the winning 2021 team, as a Football Research Analyst.\nKevin Clark, in a 2018 article for The Ringer, explained that despite not being as obvious as the sabermetrics movement in baseball, the analytics movement in the NFL is “happening in front of you all the time.” The use of analytics in the NFL did, however, predate Clark’s article. In 2014, Eagles head coach Doug Pederson explained that all decisions made by the organization - from game planning to draft strategy - were to be informed by hard data and analytics. Leading this early adoption of analytics, and reporting directly to team Vice President Howie Roseman, were Joe Douglas and Alec Halaby, “a 31-year-old Harvard grad with a job description” that had an emphasis on “integrating traditional and analytical methods in football decision-making.” The result? A “blending of old-school scouting and newer approaches” that were often only seen in other leagues, such as the NBA and MLB (Rosenthal 2018). Pederson believed in and trusted the team’s approach to analytics so much that a direct line of communication was created between the two during games, with the analytics department providing the head coach with math-based recommendations for any scenario Pederson requested (Awbrey 2020).2\nIn just under five years time since the publishing of that article, it has become hard to ignore the analytic movement within the NFL. Yet, there is still so much growth to happen in the marriage between the NFL and advanced metrics. For example, there is no denying that the sabermetrics movement drastically “altered baseball’s DNA” Heifetz (2019)]. Moreover, as explained in Seth Partnow’s outstanding The Midrange Theory: Basketball’s Evolution in the Age of Analytics, the analytics movement in the NBA essentially killed the midrange shot (briefly: it is more beneficial to try to work the ball in directly under the basket (for a high-percentage shot) or to take the 3-pointer, as the possible additional point is statistically worth more despite the lower success probability as opposed a 2-point midrange shot) as well as the traditional, “old-school” center position.\nCompared to both the NBA and MLB, the NFL is playing catch up in analytics driving changes equivalent to the death of the midrange shot or the plethora of additional tactics and changes to baseball because of sabermetrics. Joe Banner, who served as the President of the Eagles from 2001-2012 and then the Chief Executive Officer of the Browns from 2012-2013, explained that some of the hesitation to incorporate analytics into NFL game planning was a result of the game being “very much driven by conventional wisdom to an extreme degree” (Fortier 2020). Perhaps nobody encapsulates this better than Pittsburgh Steelers Head Coach Mike Tomlin. When asked about his position on analytics during the 2015 season, Tomlin explained:\nGiven that Tomlin’s quote is from 2015, perhaps the Steelers pivoted since and are now more analytically inclined. That does not seem to be the case. In a poll of NFL analytics staffers conducted by ESPN, the Steelers were voted as one of the least analytically advanced teams in the league.\nThere is large gap between the least analytically inclined teams (Washington, Tennessee, Cincinnati, New York Giants, and Pittsburgh) and those voted as the most analytically inclined (Baltimore, Cleveland, Philadelphia, and Houston). In the ESPN poll, the Browns were voted as the analytics department producing the highest level of work. One of those polled spoke to the fact that much of this outstanding work is a result of General Manager Andrew Berry being a “true believer,” explaining that he is one of the “rare guys you’ll come across in life where you think to yourself, ‘Man, this guy thinks at a different level. Just pure genius.’ He’s one of them.”\nIn his article for the Washington Post, Sam Fortier argues that many teams became inspired to more intimately introduce analytics into game planning and on-field decisions after the 2017 season. On their run to becoming Super Bowl Champions, the Philadelphia Eagles were aggressive on 4th down, going for it 26 times during the season and converting on 17 of those for a conversion percentage of 65.4%. A quick examination and visualization of data highlights the absolutely staggering increase in 4th aggressiveness among NFL head coaches from 2017-2021:\nThere has been a 96.3% increase in the number of 4th down attempts from just 2017 to 2021. In fact, the numbers may actually be higher as I was quite conservative in building the above plot by only considering those 4th down attempts that took place when the offensive team had between a 5-to-95% winning probability and those prior to the two-minute warning of either half. Even with those conservative limitations, the increase is staggering. The numbers, however, support this aggression. During week one of both the 2020 and 2021 season, not going for it on 4th down “cost teams a cumulative 170 percentage points of win probability” (Bushnell 2021).\nBen Baldwin, using the nfl4th package that is part of the nflverse, tracked the shift in NFL coaching mentality regarding 4th down decisions by comparing 2014’s “go for it percentage” against the same for 2020. When compared to the 2014 season, NFL coaches are now much more in agreement with analytics on when to “go for it” on 4th down in relation to the expected gain in win probability.\nIt should not be surprising then, considering Mike Tomlin’s quote from above and other NFL analytics staffers voting the Steelers as one of the least analytically driven teams in the league, that Pittsburgh lost the most win probability by either kicking or punting in “go for it” situations during the 2020 NFL season. On the other end, the Ravens and Browns - two teams voted as the most analytically inclined - are the two best organizations at knowing when to “go for it” on 4th down based on win probability added. There seems to be a defined relationship between teams buying into analytics and those who do not:\nThe NFL’s turn towards more aggressive 4th-down decisions is just one of the many analytics-driven changes occurring in the league. Another significant example is Defense-Adjusted Value over Average (or DVOA), a formula created by Aaron Schatz, now the editor in chief of Football Outsiders, that sought to challenge the notion that teams should, first, establish the running game in order to open up the passing game. Some of these changes are apparent on televisions screens on Sunday afternoons in the Fall, while others are occurring behind the scenes (analytics departments working on scouting and draft preparation, for example). Indeed, the use of analytics in the NFL is not as tightly ingrained as we see in other prominent leagues. And we must remember that there are certainly continued hold outs among some NFL coaches (like Mike Tomlin).\nDespite some coaching hold outs on fully embracing analytics, the “thirst for knowledge in football is as excessive as any other sport and the desire to get the most wins per dollar is just as high.” As the pipeline of data continues to grow, both internally in the league and data that becomes publicly accessible, “smart teams will continue to leave no rock unturned as they push the limits on how far data can take them.” Joe Banner explained that while the NFL has long been a league of coaches saying “well, that is the way we’ve always done it,” the league is ripe for a major shift (Bechtold 2021).\nBanner’s belief that those teams searching for every competitive advantage will “leave no rock unturned” is the driving force behind this book. For all intents and purposes, the age of analytics in the NFL is still in its infancy. Turning back, again, to the 2017 season, the Eagles’ management praised and credited the team’s analytics department as part of the reason they were able to win Super Bowl LII. Doing so Danney Heifetz argues, “changed the language of football.” The NFL, he explains, is a “copycat league” and, as witnessed with the increase in 4th down aggressiveness since 2017, teams immediately began to carbon copy Philadelphia’s approach to folding traditional football strategy with a new age analytics approach. Because of the modernity of this relationship between long-held football dogmas and analytics, nobody can be quite sure what other impacts it will create on the gamesmanship of football.\nHowever, as Heifetz opines, both the NBA and MLB can serve as a roadmap to where analytics will take the NFL. Importantly, the NFL’s relationship with analytics is still in its “first frontier of what will likely be a sweeping change over the next two decades.” Because of this, we cannot be sure what the next major impact analytics will make, nor when it may occur. But, with the ever-growing amount of publicly accessible data, it is only a matter of time until it is discovered. For example, in an interview with Heifetz, Brian Burke - one of the forefather’s of NFL analytics and now a writer for ESPN - expressed his belief that the next major impact will be “quantifying how often quarterbacks make the correct decision on the field.”\nIt seems that every new NFL season results in an amateur analyst bringing a groundbreaking model and/or approach to the table. Unlike, for example, MLB where there is little left to discover in terms of sabermetrics and new approaches to understanding the game and its associated strategy, the NFL is - for lack of a better phrase - an open playing field. With more and more data becoming available to the public, it is now easier than ever investigate your own ideas and suspicions and to create your own models to confirm your intuition.\nFor example, I am originally from the greater Pittsburgh area and am a big Steelers fan (which certainly explains some of the Steelers-centric examples I use in the writing of this book). I was adamant in my belief that Pittsburgh’s TJ Watt should win the 2021 Defensive Player of the Year award, despite many others calling for Los Angeles’ Aaron Donald to claim the title. In effort to prove my point, I sought out to design what I coined Adjusted Defensive Impact. To begin, I wanted to explore the idea that not all defensive sacks are created equal, as a player’s true impact is not always perfectly represented by top-level statistics.\nTo account for that, I opted to adjust and add statistical weight to sack statistics. This was done over multiple areas. For instance, not all players competed in all 17 regular-season games in 2021. To adjust for this, I took the total of game played in the data (2,936) and divided by 17 (a full season) to achieve a weighted adjustment of 0.0058. TJ Watt played in just 15 games in 2021. His adjusted equation, therefore, is (17-‘games’) * 0.0058. The result? He gets a bit more credit for this adjustment than, say, Myles Garrett who played all 17 regular-season games.\nGoing further with the model, I created a weighted adjustment for solo sacks (0.90), a negative weighted adjustment (-0.14) for any sack charted as “unblocked,” and a weighted adjustment to account for how many times a player actually rushed the QB compared to how many defensive snaps they played. Using data from the SIS Data Hub, the full code is below:\nThe end result? Taking into account the above adjusted defensive impact, TJ Watt was absolutely dominant during the 2021 season:\nAll of these examples - from Ben Baldwin’s 4th-down model, to Football Outsiders’ DVOA, to my attempt to further quantify defensive player impact - are just the leading edge of the burgeoning analytics movement in the NFL. Moreover, the beauty of analytics is that you do not have to be a mathematician or statistics buff in order to enter the fray. All it takes is a genuine curiosity to explore what Bob Carroll, Pete Palmer, and John Thorn coined as the “Hidden Game of Football” and the desire to learn, if you have not already, the R programming language."
  },
  {
    "objectID": "index.html#overview-of-chapters",
    "href": "index.html#overview-of-chapters",
    "title": "An Introduction to NFL Analytics with R",
    "section": "\n1.1 Overview of Chapters",
    "text": "1.1 Overview of Chapters\n\nChapter 1 provides an overview of the nflverse with specific attention paid to the difference between using nflfastR versus nflreadr. Serving as the first dive into analytics, the chapter showcases how to use nflreadr to retrieve both compiled weekly NFL stats and the deeply robust play-by-play statistics. In both cases, exercises are provided. Readers will do their first coding by, first, using the weekly stats to determine the 2021 leaders in air yards per attempt. Second, readers will use the play-by-play statistics from the 2021 season to create a brand new metric (QB aggressiveness on 3rd down pass attempts). Afterward, readers will learn how to retrieve multiple seasons of data at once.\nChapter 2 covers the process of downloading both R and RStudio, as well as the necessary packages to do NFL analytics. As one of the most important chapters in the book (especially for those new to the R programming language), readers take a deep dive into wrangling NFL data with the tidyverse package. To begin, readers will learn about the dplyr pipe (%>%) and use, in exercises, the six most important verbs in the dplyr language: filer(), select(), arrange(), summarize(), mutate(), and group_by(). At the conclusion of the chapter, multiple exercises are provided to allow readers to practice using the dplyr verbs, relational operators within the filter() function and creating “new stats” by using the summarize() function. Moreover, readers will determine the relationship between the dplyr language and important variables within the nflverse data such as player_name and player_id, which is important for correct manipulation and cleaning of data.\nChapter 3 examines the numerous and, often, bewildering amount of functions “underneath the hood” of the packages that makes up the nflverse. For example, load_pbp() and load_player_stats() are included in both nflfastR and nflreadr. However, load_nextgen_stats(), load_pfr_stats(), and load_contracts() are all part of just nflreadr. Because of this complexity, readers will learn how to efficiently operate within the nflverse. Moreover, chapter 3 provides dozens of examples and exercises related to all of the various functions included. For example, readers will learn to use load_nextgen_stats() to determine which running backs get to the line of scrimmage the quickest and will use load_pfr_stats() to explore advanced defensive metrics across multiple seasons.\nChapter 4 moves readers from data cleaning and manipulation to an introduction to data visualization using ggplot2. As well, chapter 4 provides further instruction on nflverse functions such as clean_player_names(), clean_team_abbrs(), and clean_homeaway(). As well, to prep for data visualization, readers will be introduced to the teams_colors_logos and load_rosters functions as well as the nflplotR package, which provides “functions and geoms to help visualization of NFL related analysis” (Carl 2022). Readers will produce multiple types of visualizations, including geom_bar, geom_point, geom_density, and more. As well, readers will learn to use facet_wrap and facet_grid to display data over multiple seasons. For visualizations that include team logos or player headshots, instruction will cover both how to do the coding manually using teams_colors_logos or load_rosters and to use the nflplotr package to avoid the need to use left_join to merge teams_colors_logos to your dataframe.\nChapter 5 introduces advanced methods in R using nflverse data, with a specific focus on modeling and machine learning. To streamline the process of learning, readers will be introduced to tidymodels, a “collection of packages for modeling and machine learning using tidyverse principles” (Silge, n.d.). As an example, readers will first be introduced to Tej Seth’s Rushing Yards Over Expected model (GitHub, ShinyApp). The model will serve as a learning tool to help readers understand the relationship between nflfastR data and machine learning (in Tej’s case, an xgboost model). Afterward, specific attention is given to binary classification, multiclass classification, and regression computer learning models. At the conclusion of the chapter, readers will be provided exercises to allow them to develop their own supervised and unsupervised machine learning models.\nChapter 6 introduces data from sources outside of the nflverse, including premium statistics from Pro Football Focus and Sports Info Solutions. Readers will learned to use various functions, such as clean_team_names, in order to prepare the data to merge with data from the nflverse. As well, this chapter will introduce readers to working with player tracking data. To do so, data will be provided from the NFL’s Big Data Bowl. To highlight the work being completed using player tracking, this chapter will discuss the Big Data Bowl entries of Matt Ploenzke (The Importance of Ball Carrier Downfield Acceleration and Unblocked Tackler Distance and Spacing) and the team of Kellin Rumsey & Brandon DeFlon (The Battle Between Blocker and Defender Is Often Decided by Leverage)."
  },
  {
    "objectID": "index.html#about-the-author",
    "href": "index.html#about-the-author",
    "title": "An Introduction to NFL Analytics with R",
    "section": "About The Author",
    "text": "About The Author\nI (Bradley Congelio) am currently an Assistant Professor in the College of Business at Kutztown University of Pennsylvania. Aside from my core area of instruction, I also instruct the very popular Sport Analytics (SPT 313) course.\nI earned my Ph.D. from the University of Western Ontario and received a specialized certificate in R for Data Analytics from the University of California, San Diego in 2021. I am a proud undergraduate alumni of West Liberty University and am a strong advocate of a broad-based liberal arts education.\nMy research focuses on using big data, the R programming language, and analytics to explore the impact of professional stadiums on neighboring communities. I use the proprietary Zillow ZTRAX database as well as U.S. Census and other forms of data to create robust, applied, and useful insight into how best to protect those living in areas where stadiums are proposed for construction.\nAs well, my work in sport analytics, specifically the NFL, has been featured on numerous media outlets, including the USA Today and Sports Illustrated.\nFinally, my most recent academic, peer-reviewed publications include:\n\nCongelio, B. (2022). ’Examining the Impact of New Stadium Construction on Local Property Prices Using Data Analytics and the Zillow ZTRAX Database.” Journal of Business, Economics, and Technology Spring 2022, 39-55.\nCongelio, B. (2021). “Monitoring the Policing of Olympic Host Cities: A Novel Approach Using Data Analytics and the LA2028 Olympic Summer Games.” Journal of Olympic Studies 2(2), 129-145.\nCongelio, B. “Predicting the Impact of a New Stadium on Surrounding Neighborhoods Through the Use of a k-means Unsupervised Clustering Algorithm.” Currently under peer review.\nCongelio, B. “Examining Megaevent’s Impact on Foot Traffic to Local Businesses Using Mobility and Demographic Aggregation Data.” Currently under peer review and funded by a $15,000 grant.\n\n\n1.1.1 Why A Book Instead of Working in Analytics?\nI am sometimes asked why I spend time in the classroom teaching this material rather than taking my domain knowledge to the “industry side” and working in the NFL or an otherwise NFL-connected outlet.\nThe honest and, likely boring, answer is this: I love teaching. My favorite experience in the classroom yet is always in my Sport Analytics course. The frustration and sense of helplessness is palpable in the first weeks of the semester as students attempt to wrap their head around, what a former student called, “this [censored] foreign language.” I insist that they keep pushing through the exercises and assignments. Often, there is line out my door and extending down the hallway during office hours comprised of just students from the Sport Analytics class.\nAnd then something amazing happens.\nTypically about halfway through the semester, I start seeing the light bulbs go off. Instead of cursing in anger at the “foreign language,” students begin randomly cursing in excitement as the flow of the tidyverse language “clicks.” Once that happens, it is off to the races because, once they understand speaking in tidyverse, learning more difficult packages (like tidymodels) seems doable.\nAnd that is why I teach. That moment where I realize my lecturing, assisting, explaining, and gentle nudging are all finally paying dividends - not for me, though. For the students.\nThis book serves as an extension of that classroom experience. As a reader of this book, you are now a “student” and I hope you do not hesitate to reach out to me if you ever have any questions or, more importantly, when (not if) you have that “light bulb moment” and everything begins to click for you."
  },
  {
    "objectID": "index.html#technical-details",
    "href": "index.html#technical-details",
    "title": "An Introduction to NFL Analytics with R",
    "section": "Technical Details",
    "text": "Technical Details\nThis book was written using RStudio’s Visual Editor for R Markdown. It was published using the Quarto publishing system built on Pandoc. As well, the following packages were used in this book:\n\n\n\n\nPackages Used In This Book\n \n package \n    version \n    source \n  \n\n\n dplyr \n    1.0.10 \n    CRAN (R 4.1.3) \n  \n\n ggplot2 \n    3.4.0 \n    CRAN (R 4.1.3) \n  \n\n gt \n    0.8.0 \n    CRAN (R 4.1.3) \n  \n\n nflfastR \n    4.4.0.9004 \n    https://nflverse.r-universe.dev (R 4.1.3) \n  \n\n nflreadr \n    1.3.1.07 \n    Github (nflverse/nflreadr\\@b77f17c1eb63f9df565c9560bbcb06c723e8c5c7) \n  \n\n nflverse \n    1.0.2 \n    https://nflverse.r-universe.dev (R 4.1.3) \n  \n\n scales \n    1.2.1 \n    CRAN (R 4.1.3) \n  \n\n tidymodels \n    1.0.0 \n    CRAN (R 4.1.3) \n  \n\n tidyverse \n    1.3.1 \n    CRAN (R 4.1.1) \n  \n\n webshot \n    0.5.2 \n    CRAN (R 4.1.1) \n  \n\n\n\n\nFinally, please note that this book uses the dplyr pipe operator (%>%) as opposed to the new, built-in pipe operator released with version 4.1 of R (|>). It is likely that you can work through the exercises and examples in this book by using either operator. I maintain my use of the dplyr pipe operator for no other reason than personal preference."
  },
  {
    "objectID": "index.html#license",
    "href": "index.html#license",
    "title": "An Introduction to NFL Analytics with R",
    "section": "\n1.2 License",
    "text": "1.2 License\nThe online version of this book is published with the Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0) license.\n\n\n\n\nAwbrey, Jake. 2020. “The Future of NFL Analytics.” https://www.samford.edu/sports-analytics/fans/2020/The-Future-of-NFL-Data-Analytics.\n\n\nBechtold, Taylor. 2021. “How the Analytics Movement Has Changed the NFL and Where It Has Fallen Short.” https://theanalyst.com/na/2021/04/evolution-of-the-analytics-movement-in-the-nfl/.\n\n\n“Big Data Bowl: The Annual Analytics Contest Explores Statistical Innovations in Football.” n.d. https://operations.nfl.com/gameday/analytics/big-data-bowl/.\n\n\nBushnell, Henry. 2021. “NFL Teams Are Taking 4th-down Risks More Than Ever - but Still Not Often Enough.” https://sports.yahoo.com/nfl-teams-are-taking-4th-down-risks-more-than-ever-but-still-not-often-enough-163650973.html.\n\n\nCarl, Sebastian. 2022. “nflplotR.” https://nflplotr.nflverse.com/.\n\n\nFortier, Sam. 2020. “The NFL’s Analytics Movement Has Finally Reached the Sport’s Mainstream.” https://www.washingtonpost.com/sports/2020/01/16/nfls-analytics-movement-has-finally-reached-sports-mainstream/.\n\n\nHeifetz, Danney. 2019. “We Salute You, Founding Father of the NFL’s Analytics Movement.” https://www.theringer.com/nfl-preview/2019/8/15/20806241/nfl-analytics-pro-football-focus.\n\n\nKozora, Alex. 2015. “Tomlin Prefers \"Feel over Analytics\".” http://steelersdepot.com/2015/09/tomlin-prefers-feel-over-analytics/.\n\n\nRosenthal, Gregg. 2018. “Super Bowl LII: How the 2017 Philadelphia Eagles Were Built.” https://www.nfl.com/news/super-bowl-lii-how-the-2017-philadelphia-eagles-were-built-0ap3000000912753.\n\n\nSilge, Julia. n.d. “Tidymodels.” https://tidymodels.org."
  },
  {
    "objectID": "01-nfl-analytics-and-r.html#introduction",
    "href": "01-nfl-analytics-and-r.html#introduction",
    "title": "\n2  An Introduction to NFL Analytics and the R Programming Language\n",
    "section": "\n2.1 Introduction",
    "text": "2.1 Introduction\nIt might seem odd to begin an introductory book with coding and visualization in Chapter 1, while placing information about learning the basics of the tidyverse in a later chapter. But there is good reason why I adopted this pedagogical approach in this book. As explained by Hadley Wickham and Garrett Grolemund in their outstanding book R for Data Science, the process of reading in and then cleaning data is not exactly the most exciting part of doing analytics. As evidence suggest, early excitement about and integration into a topic increases the likelihood of following up and learning the “boring” material.\nBecause of this, I follow the approach of Wickham and Grolemund and provide data that is already, for the most part, “tidied” and ready to be used. We will however, in later chapters, pull raw data directly from it source (such as nflreadr, Pro Football Reference, and Sports Info Solutions) that requires manipulation and cleaning before any significant analysis can begin.\n\n\n\n\n\n\nImportant\n\n\n\nI am assuming, while you may not have a full grasp of the tidyverse yet, that you do currently have base R and RStudio installed. If you do not, more detailed instructions are provided in Chapter 2. If you would rather jump right into this material, you can download base R and RStudio at the following links. Once both are installed, you can return to this point in the chapter to follow along.\nTo download/install base R: cran.rstudio.com\nTo download/install RStudio: RStudio Desktop (scroll to bottom of page for Mac options)\n\n\nMoreover, as briefly outlined in the Preface, we move through the process of learning NFL analytics via a close relationship with investigative inquiry. In this instance, we will define the process of investigative inquiry as one that seeks both knowledge and information about a problem/question through data-based research. To that end, we will routinely use the process throughout this book to uncover insights, patterns, and trends relating to both players and teams that serve to help us answer the problem/question we are examining.\nWhile it can - and should - be entertaining to develop visualization and models around arbitrarily picked statistics and metrics, it is important to remember that the end goal of the process is to glean useful insights that, ultimately, can be shared with the public. Much like the work done by a data analyst for a Fortune 500 company, the work you produce as a result of this book should do two things: (1.) provide deeper insight and knowledge about NFL teams and players and (2.) effectively communicate a story.\nThis is why the process of investigative inquiry is ingrained, as much as possible, into every example provided in this book. In doing so, the standard outline for completing an investigate inquiry is modified to fit the needs of this book - specifically, the addition of communicating your findings to the public at the end."
  },
  {
    "objectID": "01-nfl-analytics-and-r.html#the-investigate-inquiry-outline",
    "href": "01-nfl-analytics-and-r.html#the-investigate-inquiry-outline",
    "title": "\n2  An Introduction to NFL Analytics and the R Programming Language\n",
    "section": "\n2.2 The Investigate Inquiry Outline",
    "text": "2.2 The Investigate Inquiry Outline\n\nIdentify the problem or question. The first step in any investigative inquiry is to clearly define the problem or question that you are trying to answer. Many times, fans have questions about their individuals favorite team and/or players. For example, the 2022 Los Angeles Rams - the defending Super Bowl Champions - were eliminated from playoff contention with three weeks remaining in the season. With the early exit, the Rams tied the 1999 Denver Broncos for the earliest elimination from playoff contention for any prior Super Bowl Champion. The Rams’ early elimination can be explained by the high number of injuries during the season, including Matthew Stafford, Cooper Kupp, and Aaron Donald. Perhaps the biggest factor, though, was the inability to keep a healthy offensive line. In this specific example, in terms of identifying the problem or question, a potential problem or question to explore is: how many unique combinations of offensive linemen did the 2022 LA Rams use and where does it rank in NFL history? Have other teams in recent history faced the same amount of offensive line turnover yet still make the playoffs? As you can see, there are a number of different avenues in which the problem or question surrounding the Rams’ offensive line injury issues can be explored.\nGather data. With a question or problem determined, we now turn to the process of finding and gathering the necessary data to find answers. Unfortunately, data is not always going to be available to answer your investigate inquiry. For example, NFL’s tracking data is only released in partial form during the annual Big Data Bowl (explored later in Chapter ##). In the event that your question or problem requires data that is not available, you must loop back to Step 1 and reconfigure your question to match available data. In the case of the 2022 LA Rams’ offensive line, access to data that can answer the question is available through two cores avenues: the load_participation and load_snap_counts functions within the nflverse family of packages.\nClean and prepare the data. It is not often that the data you obtain to answer your question will be perfectly prepared to immediate analysis. As will be explored below, the data collected to explore the Rams’ offensive line combinations required both (1.) a critical thought process on how to best solve oddities in the data while still producing correct and reliable information (2.) the cleaning and preparation to make the changes as a result of that critical thinking process. As you progress through the many examples and exercises in this book, you will often be presented with prepared datasets that require you to determine the best approach to data manipulation through this critical thinking and cleaning/preparation process.\nAnalyze the data. After problem solving to ensure the data is as reliable and consistent as possible, we can turn to analyzing the data. In this case, since we are concerned with unique combinations of offensive linemen, we can quickly get results by using the n_distinct function within dplyr.\n\nVisualize the data. There are generally two options for visualizing data: plotting with ggplot or creating a table with gt and the outstanding companion package gtExtras. To that end, considering the following can help determine whether to present your findings in char or table format.\n\nThe type of data you are working with. If you have a large amount of numerical data that needs to be compared or analyzed, a table may be the most effective way to present this information. On the other hand, if you want to highlight trends or patterns in your data, a chart can help illustrate the information in a more clear manner.\nThe purpose of your visualization. You must consider what you ultimately want to communicate with your visualization. If you want to provide a detailed breakdown of your data, a table is usually more appropriate. However, if you want to show the overall trend or pattern in your data, a chart is going to be more effective.\nThe audience for your visualization. As you determine whether to use a chart or a table, think about who will be viewing your visualization and what level of detail they need. If your audience is familiar with the data and needs to see precise value, a table may be a better choice. If your audience is not as familiar with the data and you want to highlight the main trends or patterns, a chart my be more effective.\n\nBelow, we will explore visualizing our offensive linemen combinations in both chart and table format using multiple different variables for sake of comparison.\n\nInterpret and communicate the results. Lastly, it is time to communicate your results to the public. Whether this be through Twitter, a team blog, or a message board, there are numerous items to consider when preparing to build your story/narrative for sharing. This will be covered further in Chapter ## (Visualization) as well.\n\nWith a clear direction via the investigative inquiry process, we can turn to taking a deeper dive into the LA Rams’ 2022 offensive linemen issue."
  },
  {
    "objectID": "01-nfl-analytics-and-r.html#investigating-the-rams-2022-offensive-line",
    "href": "01-nfl-analytics-and-r.html#investigating-the-rams-2022-offensive-line",
    "title": "\n2  An Introduction to NFL Analytics and the R Programming Language\n",
    "section": "\n2.3 Investigating the Rams’ 2022 Offensive Line",
    "text": "2.3 Investigating the Rams’ 2022 Offensive Line\nThe “Super Bowl hangover” is real.\nAt least for the loser of the big game.\nSince the AFL and NFL merged in 1970, a total of 15 of the 51 losers of the Super Bowl went on to miss the playoffs in the following season, while 13 failed to even achieve a winning record. Teams coming off a Super Bowl victory have generally fared better, with the winners putting together a .500 record or better 45 out of 51 times.\nOf those six teams to not achieve a .500 record after winning the Super Bowl, only a few have been as downright terrible as the 2022 Los Angeles Rams.\nAs explained by Mike Ehrmann, the Rams’ poor Super Bowl defense is “what happens when a laundry list of things go wildly wrong at the same time” (Kirschner 2022). As outlined above in our investigative inquiry outline, one of the core items on the Rams’ laundry list of bad luck was the absurd amount of offensive linemen ending up on the injured list. This, combined with losing Andrew Whitworth to retirement after the Super Bowl, led to quarterback Matthew Stafford being sacked on 8.6-percent of his dropback attempts (a rate that nearly doubled from the previous season).\nGiven that context, just how historically bad was the Rams’ 2022 offensive line turnover? We can being diving into the data to find our results and build our story.\n\n2.3.1 Unique Offensive Line Combinations: How to Collect The Data?\nTo begin obtaining and preparing the data to determine the number of unique offensive line combinations the Rams had in the 2022 season, I turned to two possible options: the load_participation and load_snap_counts functions within the nflreadr package. The load_participation function will return, if include_pbp = TRUE a list of every player ID number that was on the field for each play, whereas load_snap_counts returns - on a per game basis - the percentage of snaps each player was on the field for.\nIn the end, using load_snap_counts created the most accurate, reliable, and straightforward way in each to collect unique offensive line combinations. The load_participation function resulted in several oddities in the data (not with the collection of it by the nflverse maintainers, but with individual NFL team strategies and formations). To highlight this, the following code will select the first offensive play for each team, in each game, up to week 15 of the 2022 season.\n\nparticipation <- nflreadr::load_participation(2022, include_pbp = TRUE)\nrosters <- nflreadr::load_rosters(2022) %>%\n  select(full_name, gsis_id, depth_chart_position)\n\noline_participation <- participation %>%\n  filter(play_type %in% c(\"pass\", \"run\")) %>%\n  group_by(nflverse_game_id, possession_team, fixed_drive) %>%\n  filter(fixed_drive == 1 | fixed_drive == 2) %>%\n  filter(row_number() == 1) %>%\n  select(nflverse_game_id, play_id, possession_team, \n         offense_personnel, offense_players) %>%\n  dplyr::mutate(gsis_id = stringr::str_split(offense_players, \";\")) %>%\n  tidyr::unnest(c(gsis_id)) %>%\n  left_join(rosters, by = c(\"gsis_id\" = \"gsis_id\"))\n\noline_participation <- oline_participation %>%\n  filter(depth_chart_position %in% c(\"T\", \"G\", \"C\")) %>%\n  group_by(nflverse_game_id, possession_team) %>%\n  mutate(starting_line = toString(full_name)) %>%\n  select(nflverse_game_id, possession_team, \n         offense_personnel, starting_line) %>%\n  distinct()\n\nWhile the output using the load_participation function is correct, a quick examination of the offense_personnel column causes concern about the viability of this approach to calculate the total number of unique offensive line combinations. A grouping and summing of the offense_personnel column highlights the issue.\n\noline_participation %>%\n  group_by(offense_personnel) %>%\n  summarize(total = n())\n\n# A tibble: 14 x 2\n   offense_personnel                        total\n   <chr>                                    <int>\n 1 1 RB, 0 TE, 4 WR                             3\n 2 1 RB, 1 TE, 3 WR                           229\n 3 1 RB, 2 TE, 2 WR                           165\n 4 1 RB, 3 TE, 1 WR                            17\n 5 2 QB, 1 RB, 1 TE, 2 WR                       4\n 6 2 RB, 0 TE, 3 WR                             1\n 7 2 RB, 1 TE, 2 WR                            86\n 8 2 RB, 2 TE, 1 WR                            13\n 9 3 RB, 1 TE, 1 WR                             1\n10 6 OL, 1 RB, 0 TE, 3 WR                       2\n11 6 OL, 1 RB, 1 TE, 2 WR                      12\n12 6 OL, 1 RB, 2 TE, 1 WR                       1\n13 6 OL, 2 RB, 0 TE, 2 WR                       1\n14 7 OL, 0 RB, 0 TE, 0 WR,1 P,1 LS,1 DL,1 K     1\n\n\nOf concern are rows 10 through 14. In 15 different cases, a team ran its first play of the game with six offensive linemen. And, in one case, the resulting data indicates that the Dallas Cowboys ran their first play in week 5 against the LA Rams with seven offensive linemen, one punter, one long snapper, and a kicker.\nIn the first case, the data is correct that the teams ran their first offensive play with six offensive linemen. For example, in its week 3 game against the Steelers, the data indicates the Cleveland Browns as having started Jack Conklin (tackle), Jedrick Wills Jr. (tackle), Joel Bitonio (guard), Michael Dunn (guard), Wyatt Teller (guard), and Ethan Pocic (center). A view of the NFL’s All-22 film confirms that, indeed, all six offensive linemen were on the field for the Browns’ first snap of the game.\n\n\nSteelers vs. Browns: 6 Offensive Linemen\n\n\nIn the second case, Dallas’ offense personnel on its “first play” from scrimmage is the result of the Cowboys returning a fumble for a touchdown on the Rams’ first offensive possession with a botched snap on the ensuing extra point attempt. Because of that, the extra point attempt is no longer scored as an extra_point in the play_type variable within the play-by-play data, but a rushing attempt. As a result of this oddity, the data is correct in listing Dallas’ first offensive play as coming out of an extra point personnel grouping.\nBoth of these examples are problematic as a team’s “starting offensive line” is considered to be just five players: the left tackle, the left guard, the center, the right guard, and the right tackle. In order to correctly determine the number of combinations used, we need to first determine the five most-commonly used offensive linemen for each team. Because of the off-the-wall situations that can occur in football, building offensive line combinations through personnel groupings in the play-by–play data is tricky, at best.\nBecause of this, we can turn to the load_snap_counts function with the nflreadr package to determine the number of unique offensive line combinations. The process to do so occurs over several steps and involves decision-making on our end on how best to accurately represent the five core offensive linemen for each team.\n\noline_snap_counts <- nflreadr::load_snap_counts(seasons = 2022)\n\noline_snap_counts <- oline_snap_counts %>%\n  select(game_id, week, player, position, team, offense_pct) %>%\n  filter(position %in% c(\"T\", \"G\", \"C\")) %>%\n  group_by(game_id, team) %>%\n  arrange(-offense_pct) %>%\n  slice(1:5) %>%\n  ungroup()\n\nFirst, we obtain snap count data from the 2022 season and write it into a dateframe titled oline_snap_counts. After, we select just the necessary columns and then filter out the position information to include only tackles, guards, and centers. After grouping each individual offensive line by game_id and its respective team, we arrange each player’s snap count in descending order using offense_pct.\nAnd this is where a decision needs to be made on how to best construct the five starting offensive linemen for each team. By including slice(1:5), we are essentially selecting just the five offensive linemen with the most snap counts in that singular game.\nAre these five plays necessarily the same five that started the game as the two tackles, two guards, and one center? Perhaps not. But, hypothetically, a team’s starting center could have been injured a series or two into the game and the second-string center played the bulk of the snaps in that game.\nBecause of such situations, we can make the argument that the five offensive line players with the highest percentage of snap counts for each unique game_id are to be considered the combination of players used in that game.\nNext, let’s make the decision to arrange each team’s offensive line, by game, in alphabetical order. Since we do not have a reliable way to include specific offensive line positions (that is, we have tackle instead of left tackle or right tackle), we can build our combination numbers strictly based on the five downed linemen, regardless of specific position on the line of scrimmage.\nAfter, we use the toString function to place all five names into a single column (starting_line) and then filter out the data to include just one game_id for the linemen.\n\noline_snap_counts <- oline_snap_counts %>%\n  group_by(game_id, team) %>%\n  arrange(player, .by_group = TRUE)\n\noline_final_data <- oline_snap_counts %>%\n  group_by(game_id, week, team) %>%\n  mutate(starting_line = toString(player)) %>%\n  select(game_id, week, team, starting_line) %>%\n  distinct(game_id, .keep_all = TRUE)\n\nThe end result includes the game_id, the week, the team abbreviation, and the starting_line column that includes the names of the five offensive line players with the highest snap count percentage for that specific game.\n\nhead(oline_final_data)\n\n# A tibble: 6 x 4\n# Groups:   game_id, week, team [6]\n  game_id          week team  starting_line                                     \n  <chr>           <int> <chr> <chr>                                             \n1 2022_01_BAL_NYJ     1 BAL   Ben Powers, Kevin Zeitler, Morgan Moses, Patrick ~\n2 2022_01_BAL_NYJ     1 NYJ   Alijah Vera-Tucker, Connor McGovern, George Fant,~\n3 2022_01_BUF_LA      1 BUF   Dion Dawkins, Mitch Morse, Rodger Saffold, Ryan B~\n4 2022_01_BUF_LA      1 LA    Brian Allen, Coleman Shelton, David Edwards, Jose~\n5 2022_01_CLE_CAR     1 CAR   Austin Corbett, Brady Christensen, Ikem Ekwonu, P~\n6 2022_01_CLE_CAR     1 CLE   Ethan Pocic, James Hudson, Jedrick Wills Jr., Joe~\n\n\nWith the data cleaned and prepared, we are now able to take our first look at the results. In the code below, we are grouping by all 32 NFL team and then summarizing the total number of unique offensive line combinations used through the first 15 weeks of the 2022 season.\n\ntotal_combos <- oline_final_data %>%\n  group_by(team) %>%\n  summarize(combos = n_distinct(starting_line)) %>%\n  arrange(-combos)\n\nDespite much of the media focus being on the Rams’ poor performance, given their title of defending Super Bowl Champions, the Arizona Cardinals had nearly as many unique offensive line combinations at the conclusion of the 2022 regular season.\nWith the data cleaned and prepared, let’s use it to create a ggplot graph and, to do so, compare the relationship between a team’s number of unique offensive lines against its winning percentage. To complete this, we first need to join the winning percentages to our existing total_combos dataframe.\nTo bring in the individual winning percentages, we will use the get_nfl_standings function from espnscrapeR and then combine the two sets of data on team abbreviations via a left_join. Unfortunately, the team abbreviation returned from espnscrapeR does not match up with those used in the nflverse for both the Los Angeles Rams and the Washington Commanders (LAR vs. LA and WSH vs. WAS). As evidenced in the below code, correcting this issue is simple with the clean_team_abbrs function in the nflreadr package.\n\nrecords <- espnscrapeR::get_nfl_standings(season = 2022) %>%\n  select(team_abb, win_pct)\n\nrecords$team_abb <- nflreadr::clean_team_abbrs(records$team_abb)\n\ntotal_combos <- total_combos %>%\n  left_join(records, by = c(\"team\" = \"team_abb\"))\n\nAfter collecting team records and merging them into the offensive line combination data, we can use ggplot to visualize the data. Individual team logos are used in place of the typical geom_point by using the nflplotR package.\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nPlease note in the below ggplot coding that we are using a custom theme, nfl_analytics_theme(). If you wish to replicate the below visualization using the theme, run the below code to place the theme into your RStudio environment allowing you to call it within ggplot.\nIf you do not have the “Roboto Condensed” font installed, ggplot will give an error message but ultimately replace it with another font on your system. If you wish to install “Roboto Condensed,” you can do so with the showtext package.\n\n\n\nnfl_analytics_theme <- function(..., base_size = 12) {\n  \n  theme(\n    panel.grid.minor = element_blank(),\n    panel.grid.major =  element_line(color = \"#d0d0d0\"),\n    panel.background = element_rect(fill = \"#f7f7f7\", color = NA),\n    plot.background = element_rect(fill = \"#f7f7f7\", color = NA),\n    panel.border = element_blank(),\n    strip.background = element_blank(),\n    plot.margin = margin(0, 1, 0.5, unit = \"cm\"),\n    axis.ticks = element_blank(),\n    text = element_text(family = \"Roboto Condensed\", size = base_size),\n    axis.text = element_text(face = \"bold\", color = \"black\", size = base_size),\n    axis.title = element_text(face = \"bold\", size = rel(1.1)),\n    axis.title.x = element_text(margin = margin(0.5, 0, 0, 0, unit = \"cm\"), size = 11),\n    axis.title.y = element_text(margin = margin(0, 0.2, 0, 0, unit = \"cm\"), size = 11, angle =90),\n    plot.title = element_text(face = \"bold\", size = rel(1.67), hjust = .1, vjust = -2),\n    plot.title.position = \"plot\",\n    plot.subtitle = element_text(size = 16, margin = margin(0.2, 0, 1, 0, unit = \"cm\"), hjust = .01, vjust = -1),\n    plot.caption = element_text(size = 10, margin = margin(0, 0, 0, 0, unit = \"cm\"), hjust = 0),\n    strip.text = element_text(size = rel(1.33), face = \"bold\"),\n    aspect.ratio = 9/16,\n    ...\n  )}\n\n\nggplot(data = total_combos, aes(x = combos, y = win_pct)) +\n  geom_smooth(se = FALSE, formula = 'y ~ x', method = \"lm\") +\n  nflplotR::geom_nfl_logos(aes(team_abbr = team), width = 0.065, alpha = 0.7) +\n  scale_x_reverse(breaks = scales::pretty_breaks(n = 12)) +\n  scale_y_continuous(breaks = scales::pretty_breaks(n = 6),\n                     labels = scales::label_number(accuracy = 0.001)) +\n  nfl_analytics_theme() +\n  xlab(\"# of Unique Offensive Line Combinations\") +\n  ylab(\"Win Percentage\") +\n  labs(title = \"# of Unique Offensive Line Combinations vs. Win Percentage\",\n       subtitle = \"Through Week #15\")\n\n\n\n\n\n\n\nAs can be seen in the resulting graph - despite a slight correlation - there are still teams with worse records than the Rams and Cardinals that have fewer unique offensive line combinations (the Houston Texans and the Chicago Bears, for example). Perhaps there is a better metric that correlates more strongly with a team’s number of offensive line combinations?\nTo begin exploring that, we can hypothesize that more offensive line combinations leads to more quarterback pressures and an increased pressure rate as the various member of the offensive line never have time to properly “gel.”\nRather than calculate the data ourselves (which is the total number dropbacks divided by the total number of pressures), we can turn away from nflverse data and retrieve the information from the SIS Data Hub. After downloading the spreadsheet, we can read it into the RStudio environment using vroom and then merge the information into our existing total_combos by matching on the individual team abbreviations.\n\npressure_rate <- vroom::vroom(\"./example_data/csv/ch1_pressurerate.csv\")\n\ntotal_combos <- total_combos %>%\n  left_join(pressure_rate, by = c(\"team\" = \"team_abbr\"))\n\n\n\n# A tibble: 6 x 3\n  season team_abbr pressure_percent\n   <dbl> <chr>                <dbl>\n1   2022 KC                    34.2\n2   2022 PHI                   30.7\n3   2022 SEA                   34.8\n4   2022 CIN                   29.4\n5   2022 SF                    32.4\n6   2022 MIA                   35  \n\n\nWith the pressure rate now merged with our unique offensive line combination data, we can make slight adjustments to our prior ggplot code to examine any potential relationship.\n\nggplot(data = total_combos, aes(x = combos, y = pressure_percent)) +\n  geom_smooth(se = FALSE, formula = 'y ~ x', method = \"lm\") +\n  nflplotR::geom_nfl_logos(aes(team_abbr = team), width = 0.065, alpha = 0.7) +\n  scale_x_reverse(breaks = scales::pretty_breaks(n = 12)) +\n  scale_y_continuous(breaks = scales::pretty_breaks(n = 6),\n                     labels = scales::percent_format(scale = 1, accuracy = 0.1)) +\n  nfl_analytics_theme() +\n  xlab(\"# of Unique Offensive Line Combinations\") +\n  ylab(\"Pressure Rate (per Dropback)\") +\n  labs(title = \"# of Unique Offensive Line Combinations vs. Pressure Rate\",\n       subtitle = \"Through Week #15\")\n\n\n\n\n\n\n\nfffffffffffffffffffffffffffff\n\npbp <- nflreadr::load_pbp(2022)\n\nexplosive <- pbp %>%\n  filter(!is.na(posteam) & !is.na(yards_gained) & fixed_drive_result == \"Touchdown\") %>%\n  filter(play_type != \"kickoff\" & play_type != \"extra_point\" & !is.na(down)) %>%\n  select(posteam, game_id, drive, yards_gained)\n  \nexplosive_per_td <- explosive %>%\n  group_by(posteam, game_id, drive) %>%\n  summarize(max_yards = max(yards_gained)) %>%\n  mutate(explosive_play = if_else(max_yards >= 20, 1, 0))\n\nexplosive_final <- explosive_per_td %>%\n  group_by(posteam) %>%\n  summarize(\n    tds_no_explosive = sum(explosive_play == 0),\n    tds_explosive = sum(explosive_play == 1)\n  )\n\ntotal_drives_calc <- pbp %>%\n  group_by(posteam, week) %>%\n  filter(!is.na(posteam) & fixed_drive_result == \"Touchdown\") %>%\n  summarize(total_drives = n_distinct(fixed_drive))\n\ntotal_drives_calc <- total_drives_calc %>%\n  group_by(posteam) %>%\n  summarize(total_drives = sum(total_drives))\n\nexplosive_final <- explosive_final %>%\n  left_join(total_drives_calc, by = c(\"posteam\" = \"posteam\")) %>%\n  mutate(percent_no_exp = tds_no_explosive / total_drives,\n         percent_w_exp = tds_explosive / total_drives) %>%\n  select(posteam, percent_no_exp, percent_w_exp)\n\nggplot(explosive_final, aes(y = reorder(posteam, percent_w_exp), x = percent_w_exp)) +\n  ggplot2::geom_col(aes(color = posteam, fill = posteam), width = 0.5) +\n  nflplotR::scale_color_nfl(type = \"secondary\") +\n  nflplotR::scale_fill_nfl(alpha = 0.4) +\n  nfl_analytics_theme() +\n  theme(axis.text.y = element_nfl_logo(size = .65)) +\n  scale_x_continuous(expand = c(0,0),\n                     breaks = scales::pretty_breaks(),\n                     label = scales::percent_format()) +\n  xlab(\"Percent of TD Drives with an Explosive Play (20+ Yards)\") +\n  ylab(\"\")\n\n\n\n\n\nKirschner, Alex. 2022. “The Rams’ Super Bowl Afterparty Turned into a Historic Hangover.” https://fivethirtyeight.com/features/the-rams-super-bowl-afterparty-turned-into-a-historic-hangover/."
  },
  {
    "objectID": "02-nfl-analytics-tidyverse.html#downloading-r-and-rstudio",
    "href": "02-nfl-analytics-tidyverse.html#downloading-r-and-rstudio",
    "title": "\n3  Wrangling NFL Data in the tidyverse\n",
    "section": "\n3.1 Downloading R and RStudio",
    "text": "3.1 Downloading R and RStudio"
  },
  {
    "objectID": "02-nfl-analytics-tidyverse.html#installing-necessary-packages",
    "href": "02-nfl-analytics-tidyverse.html#installing-necessary-packages",
    "title": "\n3  Wrangling NFL Data in the tidyverse\n",
    "section": "\n3.2 Installing Necessary Packages",
    "text": "3.2 Installing Necessary Packages"
  },
  {
    "objectID": "02-nfl-analytics-tidyverse.html#the-tidyverse-and-its-verbs",
    "href": "02-nfl-analytics-tidyverse.html#the-tidyverse-and-its-verbs",
    "title": "\n3  Wrangling NFL Data in the tidyverse\n",
    "section": "\n3.3 The tidyverse and Its Verbs",
    "text": "3.3 The tidyverse and Its Verbs\nThe tidyverse is a collection of R packages designed for data manipulation, visualization, and analysis. It was developed by Hadley Wickham, the Chief Scientist at RStudio, and a varied team of contributors. The goal of the tidyverse is to provide a consistent, easy-to-understand set of functions and syntax for working with data in R.\nThe core principle of the tidyverse is “tidy data,” which is the development team’s belief in creating a standard way of organizing data sets so that they can be easily manipulated, visualized, and analyzed. To that end, a “tidy” data set is one that is comprised of observations (rows) and variables (columns) with each variable being a distinct piece of information and each observation being a unit of analysis.\nInstalling and loading the tidyverse results eight of the core packages automatically being loaded and ready to use:\n\n\ndplyr: “dplyr provides a grammar of data manipulation, providing a consistent set of verbs that solve the most common data manipulation challenges.”\n\ntidyr: “tidyr provides a set of functions that help you get to tidy data. Tidy data is data with a consistent form: in brief, every variable goes in a column, and every column is a variable.”\n\nreadr: “readr provides a fast and friendly way to read rectangular data (like csv, tsv, and fwf). It is deigned to flexibly parse many types of data found in the wild, while still cleanly failing when data unexpectedly changes.”\n\npurrr: “purrr enhances R’s functional programming (FP) toolkit by providing a complete and consistent set of tools for working with functions and vectors. Once you master the basic concepts, purrr allows you to replace many for loops with code that is easier to write and more expressive.”\n\ntibble: “tibble is a modern re-imagining of the data frame, keeping what time has proven to be effective, and throwing out what it has not. Tibbles are data.frames that are lazy and surly; they do less and complain more forcing you to confront problems earlier, typically leading to cleaner, more expressive code.”\n\nstringr: “stringr provides a cohesive set of functions designed to make working with strings as easy as possible. It is built on top of stringi, which uses the ICU C library to provide fast, correct implementations of common string manipulations.”\n\nforcats: “forcats provides a suite of useful tools that solve common problems with factors. R uses factors to handle categorical variables, variables that have a fixed and known set of possible values.”\n\nggplot2: “ggplot2 is a system for declaratively creating graphics, based on The Grammar of Graphics. You provide the data, tell ggplot2 how to map the variables to aesthetics, what graphical primitives to use, and it takes care of the details” (Wickham 2022).\n\nAside from the core eight packages, the tidyverse will also install a multiple of other packages such as rvest (for web scraping), readxl (for reading Excel sheets in the RStudio environment), lubridate (a very powerful tool for working with times and dates), and magrittr (the package that provides the pipe %>%). As well, prior versions of the tidyverse utilized the modelr. Modeling is now handled in the tidyverse by the tidymodels package."
  },
  {
    "objectID": "02-nfl-analytics-tidyverse.html#the-flow-of-the-tidyverse",
    "href": "02-nfl-analytics-tidyverse.html#the-flow-of-the-tidyverse",
    "title": "\n3  Wrangling NFL Data in the tidyverse\n",
    "section": "\n3.4 The Flow of the tidyverse\n",
    "text": "3.4 The Flow of the tidyverse\n\nThe underlying design of coding in the tidyverse, aside from the dplyr verbs are both the assignment statement (<-)"
  },
  {
    "objectID": "02-nfl-analytics-tidyverse.html#working-with-nfl-data-and-the-dplyr-verbs",
    "href": "02-nfl-analytics-tidyverse.html#working-with-nfl-data-and-the-dplyr-verbs",
    "title": "\n3  Wrangling NFL Data in the tidyverse\n",
    "section": "\n3.5 Working With NFL Data and the dplyr Verbs",
    "text": "3.5 Working With NFL Data and the dplyr Verbs\nOf the packages nestled within the tidyverse, dplyr is perhaps the most important in terms of wrangling and cleaning data. As mentioned above, dplyr is a powerful tool for data manipulation in R as it provides a key set of functions, known as verbs, that are designed to be easy to user and understand. The verbs can be used to filter, group, summarize, rearrange, and transform all types of data sets. For those just starting their NFL analytics endeavors in the R programming language, the following four dplyr verbs are perhaps the most important. Specific examples of working with these verbs, as well as others, follow below.\n\n\nfilter: the filter verb allows you to subset data based on certain criteria. For example, you can use filter() to keep only those rows in a data set where a certain variable meets a certain conditions (ie., more than 100 completed passes). Moreover, the filter verb can be used in conjunction with logical operators such as & and | to create more complex criteria.\n\ngroup_by: the group_by() verb allows you to group a data set by one or more variables. It is a useful tool when you want to perform an operation on each group, such as calculating a summary statistic (ie, intended air yards per quarterback) or when creating a plot.\n\nsummarize: the summarize() verb allows you to reduce a data set to a single summary value. The summarize() verb is often used in conjunction with the group_by function, allowing you to group the data by one or more variables. The summarize() verb allows for a wide range of summary statistics, including means, medians, standard deviations, and more. You can also use it to calculate custom summary statistics.\n\n`mutate`: the mutate verbs allows you to create new variables within your data while also preserving existing ones.\n\n\n3.5.1 NFL Data and the filter() verb\nffffff\n\n\n\nLogical Operator\nMeaning\n\n\n\n==\nequal to\n\n\n!=\nnot equal to\n\n\n<\nless than\n\n\n<=\nless than or equal to\n\n\n>\ngreater than\n\n\n>=\ngreater than or equal to\n\n\n!\nnot\n\n\n&\nand\n\n\n|\nor\n\n\n%in%\nincludes\n\n\nis.na\nchecks for missing values\n\n\n\n\n\n3.5.2 NFL Data and the group_by() verb\nAs mentioned above, the group_by verb allows you to group data by one or more specific variables in order to conducted, among other actions, summary statistics. To showcase how group_by is used within the nflverse data, let’s first gather the 2022 regular season statistics and then use the summarize verb to get the average success rate on rushing plays.\nAs well, we immediately make use of the filter function to do sort the data : (1.) we first instruct to filter the data to include just those instances where the play_type equals run, (2.) we then say it must also be play == 1, meaning there was no penalty or other interruption that “cancelled out” the play, and (3.) we lastly pass the argument that the down cannot be missing by using !is.na as a missing down is indicative of a two-point conversion attempt.\n\n\n\n\nrushing_success_ungrouped <- pbp %>%\n  filter(play_type == \"run\" & play == 1 & !is.na(down)) %>%\n  summarize(success_rate = mean(success))\n\nrushing_success_ungrouped\n\n# A tibble: 1 x 1\n  success_rate\n         <dbl>\n1        0.430\n\n\nWithout including the group_by verb within the above code, the output is the average success rate for rushing plays for all 32 NFL teams, wherein success rate is the percentage of rushing plays that resulted in an EPA above zero. In this case, approximately 43% of NFL rushes had a positive success rate.\nThat said, we are interested in examining the success rate by team, not league-wide average. To do so, we add the posteam variable into the group_by verb.\n\nrushing_success_grouped <- pbp %>%\n  filter(play_type == \"run\" & play == 1 & !is.na(down)) %>%\n  group_by(posteam) %>%\n  summarize(success_rate = mean(success)) %>%\n  arrange(-success_rate)\n\nrushing_success_grouped %>%\n  slice(1:10)\n\n# A tibble: 10 x 2\n   posteam success_rate\n   <chr>          <dbl>\n 1 PHI            0.523\n 2 BUF            0.494\n 3 BAL            0.483\n 4 GB             0.476\n 5 KC             0.471\n 6 PIT            0.470\n 7 ATL            0.463\n 8 LV             0.449\n 9 CLE            0.448\n10 NYG            0.446\n\n\nIn the above example, we have added the offensive team into the group_by verb, while also arranging the data in descending order by success_rate, and then used slice to gather just the ten teams with the highest rushing success rate. The Philadelphia Eagles led the NFL in rushing success rate during the 2022 NFL regular season at 52.3%. By removing the slice function in the above example, we can see that Tampa Bay maintained the worst rushing success rate in the league at 37.3%.\nWhile determining the rushing success rate of teams is interesting, we can also determine the same metric for individual running backs as well. To do so, we simply replace the variable in the group_by verb. In the below example, we replace the posteam variable with the rusher variable to see which running backs have the highest success rate.\n\nrunning_back_success <- pbp %>%\n  filter(play_type == \"run\" & play == 1 & !is.na(down)) %>%\n  group_by(rusher) %>%\n  summarize(success_rate = mean(success)) %>%\n  arrange(-success_rate)\n\nrunning_back_success %>%\n  slice(1:10)\n\n# A tibble: 10 x 2\n   rusher      success_rate\n   <chr>              <dbl>\n 1 A.Davis                1\n 2 B.Aiyuk                1\n 3 B.Allen                1\n 4 B.Skowronek            1\n 5 C.Kmet                 1\n 6 C.Sutton               1\n 7 C.Wilson               1\n 8 D.Bellinger            1\n 9 D.Brown                1\n10 D.Gray                 1\n\n\nThe output, unfortunately, is not all that helpful. Because we did not use the filter verb to stipulate a minimum number of rushing attempts, the output is saying that - for example, Daniel Bellinger, a tight end, has among the most successful rushers in the league with a 100% rushing success rate. To correct this, we must add a second metric to our summarize verb (we will call it n_rushes) and then use the filter verb afterwards to include a minimum number of rushes required to be included in the final output.\nAs well, we will provide an additional argument in the first filter verb that stops the output from including any rushing attempt that does not include the running back’s name. The n_rushes() in the summarize verb allows use to now include the number of attempts, per individual rusher, that fall within the first filter parameter. Afterwards, we include a second filter argument to include just those rushers with at least 200 attempts.\n\nrunning_back_success_min <- pbp %>%\n  filter(play_type == \"run\" & play == 1 & !is.na(down) & !is.na(rusher)) %>%\n  group_by(rusher) %>%\n  summarize(success_rate = mean(success), n_rushes = n()) %>%\n  filter(n_rushes >= 200) %>%\n  arrange(-success_rate)\n\nrunning_back_success_min %>%\n  slice(1:10)\n\n# A tibble: 10 x 3\n   rusher      success_rate n_rushes\n   <chr>              <dbl>    <int>\n 1 M.Sanders          0.490      259\n 2 A.Jones            0.465      213\n 3 J.Jacobs           0.444      340\n 4 N.Chubb            0.434      302\n 5 T.Allgeier         0.429      210\n 6 Ja.Williams        0.427      262\n 7 E.Elliott          0.420      231\n 8 B.Robinson         0.420      205\n 9 A.Ekeler           0.417      204\n10 D.Foreman          0.414      203\n\n\nUnsurprisingly, Miles Sanders - a running back for the Eagles, who lead the NFL in team success rate - is the leader in rushing success among individual players with 49% of his attempts gaining positive EPA.\n\n3.5.3 NFL Data and the summarize() verb\nAs we’ve seen, the summarize function can be used to find summary statistics based whichever option we pass to it via the group_by verb. However, it can also be used to create new metrics built off data included in the nflverse play-by-play data.\nFor example, let’s examine which teams were the most aggressive on 3rd and short passing attempts during the 2022 season. Of course, determining our definition of both what “short” is on 3rd down and “aggressive” is quite subjective. For the purposes of this example, however, let’s assume that 3rd and short is considered 3rd down with five or less yards to go and that “aggressive” is a quarterback’s air yards being to, at minimum, the first-down marker.\nMust like our above examples working with rushing success rate, we begin constructing the metric with the filter argument. In this case, we are filtering for just pass plays, we want the down to equal 3, the yards to go to be equal to or less than 5, we want it to be an official play, and we do not want it to be missing the down information. After the initial filter process, we include the posteam variable within our group_by verb.\nIn our summarize section, we are first getting the total number of times each team passed the ball on 3rd down with no more than five yards to go. After, we are creating a new aggressiveness column that counts the number of times a quarterback’s air yards were, at minimum, the required yards for a first down. Next, we create another new column titled percentage that takes aggressiveness and divides it by total.\n\nteam_aggressiveness <- pbp %>%\n  filter(play_type == \"pass\" & down == 3 & ydstogo <= 5 & play == 1 & !is.na(down)) %>%\n  group_by(posteam) %>%\n  summarize(total = n(),\n            aggressiveness = sum(air_yards >= ydstogo, na.rm = TRUE),\n            percentage = aggressiveness / total) %>%\n  arrange(-percentage)\n\nteam_aggressiveness %>%\n  slice(1:10)\n\n# A tibble: 10 x 4\n   posteam total aggressiveness percentage\n   <chr>   <int>          <int>      <dbl>\n 1 LV         60             50      0.833\n 2 BUF        54             41      0.759\n 3 ARI        58             44      0.759\n 4 TB         86             64      0.744\n 5 PIT        79             58      0.734\n 6 SF         60             44      0.733\n 7 NE         54             39      0.722\n 8 SEA        54             39      0.722\n 9 MIA        59             41      0.695\n10 PHI        39             27      0.692\n\n\nThe Las Vegas Raiders, based on our definitions, are the most aggressive passing team in the league on 3rd and short as just over 83% of their air yards were at - or past - the required yardage for a first down. On the other end of the spectrum, the New York Giants were the least aggressive team during the 2022 regular season, at 49.1%.\n\n3.5.4 NFL Data and the mutate() verb\nIn the our example above working with the summarize verb, our output includes only the information contained in our group_by and then whatever information we provided in the summarize() (such as total, aggressiveness, and percentage).\nWhat if, however, you wanted to create new variables and then summarize() those? That is where the mutate verb is used.\nAs an example, let’s explore individual quarterback’s average completion percentage over expected for specific air yard distances. To start, we can attempt to do this simply by including both passer and air_yards in the group_by verb.\n\nairyards_cpoe <- pbp %>%\n  group_by(passer, air_yards) %>%\n  summarize(avg_cpoe = mean(cpoe, na.rm = TRUE))\n\nYour output is going to include the avg_cpoe for each quarterback at each and every distance of air_yards. Not only is it difficult to find meaning in, but it would prove to be difficult - if not impossible - to visualize with ggplot. To correct this issue, we must use the mutate verb.\nRather than summarize the completion percentage over expected for each distance of air_yards, we can use the mutate verb to bundle together a grouping of distances. In the below example, we are using the mutate verb to create a new variable titled ay_distance using the case_when verb.\n\nairyards_cpoe_mutate <- pbp %>%\n  filter(!is.na(cpoe)) %>%\n  mutate(\n    ay_distance = case_when(\n      air_yards < 0 ~ \"Negative\",\n      air_yards >= 0 & air_yards < 10 ~ \"Short\",\n      air_yards >= 10 & air_yards < 20 ~ \"Medium\",\n      air_yards >= 20 ~ \"Deep\")) %>%\n  group_by(passer, ay_distance) %>%\n  summarize(avg_cpoe = mean(cpoe))\n\nWith the air_yards data now binned into four different groupings, we can examine quarterbacks at specific distances.\n\nairyards_cpoe_mutate %>%\n  filter(ay_distance == \"Medium\") %>%\n  arrange(-avg_cpoe) %>%\n  slice(1:10)\n\n# A tibble: 80 x 3\n# Groups:   passer [80]\n   passer     ay_distance avg_cpoe\n   <chr>      <chr>          <dbl>\n 1 A.Brown    Medium        -6.94 \n 2 A.Cooper   Medium       -43.1  \n 3 A.Dalton   Medium         5.17 \n 4 A.Rodgers  Medium         2.02 \n 5 B.Allen    Medium        44.5  \n 6 B.Hoyer    Medium       -44.0  \n 7 B.Mayfield Medium       -15.4  \n 8 B.Perkins  Medium         0.266\n 9 B.Purdy    Medium        12.3  \n10 B.Rypien   Medium        18.0  \n# ... with 70 more rows"
  },
  {
    "objectID": "02-nfl-analytics-tidyverse.html#core-skills-for-tidy-data",
    "href": "02-nfl-analytics-tidyverse.html#core-skills-for-tidy-data",
    "title": "\n3  Wrangling NFL Data in the tidyverse\n",
    "section": "\n3.6 Core Skills for Tidy Data",
    "text": "3.6 Core Skills for Tidy Data\n\n3.6.1 Importing Data\n\n3.6.2 Dealing with Missing Data\n\n3.6.3 Changing Variable Types\n\n3.6.4 Creating New Variables\n\n3.6.5 Writing Tidy Functions\n\n3.6.6 Merging Multiple Sets of Data\n\n\n\n\nWickham, Hadley. 2022. “Tidyverse Packages.” https://www.tidyverse.org/packages/."
  },
  {
    "objectID": "03-nfl-analytics-functions.html#nflreadr-an-introduction-to-the-data",
    "href": "03-nfl-analytics-functions.html#nflreadr-an-introduction-to-the-data",
    "title": "\n4  NFL Analytics with the nflverse Family of Packages\n",
    "section": "\n4.1 nflreadr: An Introduction to the Data",
    "text": "4.1 nflreadr: An Introduction to the Data\nThe most important part of the nflverse is, of course, the data. To begin, we will examine the core data that underpins the nflverse: weekly player stats and the more detailed play-by–play data. Using nflreadr, the end user is able to collect weekly top-level stats via the load_player_stats() function or the much more robust play-by-play numbers by using the load_pbp() function.\nAs you may imagine, there is a very important distinction between the load_player_stats() and load_pbp(). As mentioned, load_player_stats() will provide you with weekly, pre-calculated statistics for either offense or kicking. Conversely, load_pbp() will provide over 350 metrics for every single play of every single game dating back to 1999.\nThe load_player_stats() function includes the following offensive information:\n\noffensive.stats <- nflreadr::load_player_stats(2021)\nls(offensive.stats)\n\n [1] \"air_yards_share\"             \"attempts\"                   \n [3] \"carries\"                     \"completions\"                \n [5] \"dakota\"                      \"fantasy_points\"             \n [7] \"fantasy_points_ppr\"          \"headshot_url\"               \n [9] \"interceptions\"               \"pacr\"                       \n[11] \"passing_2pt_conversions\"     \"passing_air_yards\"          \n[13] \"passing_epa\"                 \"passing_first_downs\"        \n[15] \"passing_tds\"                 \"passing_yards\"              \n[17] \"passing_yards_after_catch\"   \"player_display_name\"        \n[19] \"player_id\"                   \"player_name\"                \n[21] \"position\"                    \"position_group\"             \n[23] \"racr\"                        \"receiving_2pt_conversions\"  \n[25] \"receiving_air_yards\"         \"receiving_epa\"              \n[27] \"receiving_first_downs\"       \"receiving_fumbles\"          \n[29] \"receiving_fumbles_lost\"      \"receiving_tds\"              \n[31] \"receiving_yards\"             \"receiving_yards_after_catch\"\n[33] \"recent_team\"                 \"receptions\"                 \n[35] \"rushing_2pt_conversions\"     \"rushing_epa\"                \n[37] \"rushing_first_downs\"         \"rushing_fumbles\"            \n[39] \"rushing_fumbles_lost\"        \"rushing_tds\"                \n[41] \"rushing_yards\"               \"sack_fumbles\"               \n[43] \"sack_fumbles_lost\"           \"sack_yards\"                 \n[45] \"sacks\"                       \"season\"                     \n[47] \"season_type\"                 \"special_teams_tds\"          \n[49] \"target_share\"                \"targets\"                    \n[51] \"week\"                        \"wopr\"                       \n\n\nAs well, switching the stat_type to “kicking” provides the following information:\n\nkicking.stats <- nflreadr::load_player_stats(2021, stat_type = \"kicking\")\nls(kicking.stats)\n\n [1] \"fg_att\"              \"fg_blocked\"          \"fg_blocked_distance\"\n [4] \"fg_blocked_list\"     \"fg_long\"             \"fg_made\"            \n [7] \"fg_made_0_19\"        \"fg_made_20_29\"       \"fg_made_30_39\"      \n[10] \"fg_made_40_49\"       \"fg_made_50_59\"       \"fg_made_60_\"        \n[13] \"fg_made_distance\"    \"fg_made_list\"        \"fg_missed\"          \n[16] \"fg_missed_0_19\"      \"fg_missed_20_29\"     \"fg_missed_30_39\"    \n[19] \"fg_missed_40_49\"     \"fg_missed_50_59\"     \"fg_missed_60_\"      \n[22] \"fg_missed_distance\"  \"fg_missed_list\"      \"fg_pct\"             \n[25] \"gwfg_att\"            \"gwfg_blocked\"        \"gwfg_distance\"      \n[28] \"gwfg_made\"           \"gwfg_missed\"         \"pat_att\"            \n[31] \"pat_blocked\"         \"pat_made\"            \"pat_missed\"         \n[34] \"pat_pct\"             \"player_id\"           \"player_name\"        \n[37] \"season\"              \"season_type\"         \"team\"               \n[40] \"week\"               \n\n\nWhile the data returned is not as rich as the play-by-play data we will covering next, the load_player_stats() function is extremely helpful when you need to quickly (and correctly!) recreate the official stats listed on either the NFL’s website or on Pro Football Reference.\nAs an example, let’s say you need to get Ben Roethlisberger’s total passing yard and attempts from the 2021 season. You could do so via load_pbp() but, if you do not need further context, using load_player_stats() is much more efficient.\n\n4.1.1 Getting Weekly Player Stats via load_player_stats()\n\nIf you are familiar with R, it might seem logical to do the following to get Roethlisberger’s total passing yards and number of attempts from the 2021 regular season:\n\nweekly.data <- nflreadr::load_player_stats(2021)\n\nben.weekly <- weekly.data %>%\n  group_by(player_id, player_name) %>%\n  filter(season_type == \"REG\" & player_name == \"B.Roethlisberger\") %>%\n  summarize(total.yards = sum(passing_yards),\n            n.attempts = sum(attempts))\n\ntibble(ben.weekly)\n\n# A tibble: 1 x 4\n  player_id  player_name      total.yards n.attempts\n  <chr>      <chr>                  <dbl>      <int>\n1 00-0022924 B.Roethlisberger        3740        605\n\n\nAs you can see in the ben.weekly output, we have matched his official 2021 regular stats perfectly with 3,740 passing yards on 605 attempts. The code we just created is doing several things. First, we are using nflreadr::load_player_stats(2021) to place the data into our R environment in a DF titled weekly.data.\nNext, we group the data together by alike player_id (as every individual player has a unique ID number) as well as the player’s actual name. At the filtering level, we are looking for just the regular season (REG) within season_type and also removing all quarterbacks except for Ben Roethlisberger. It is important to note that player names are just first initial and last name, without a space after the period.\nAfter filtering for the regular season, we are able to summarize all of the weekly data into combined statistics by summing the weekly totals of passing yards and attempts.\nHowever, filtering by player_name can lead to significant issues with your results. An excellent example of this is Josh Allen. Let’s recreate the code above that successfully provided Roethlisberger’s stats, but replace Ben with Josh Allen:\n\njosh.allen <- weekly.data %>%\n  group_by(player_name) %>%\n  filter(player_name == \"J.Allen\" & season_type == \"REG\") %>%\n  summarize(total.yards = sum(passing_yards),\n            n.attempts = sum(attempts))\n\ntibble(josh.allen)\n\n# A tibble: 1 x 3\n  player_name total.yards n.attempts\n  <chr>             <dbl>      <int>\n1 J.Allen            4407        646\n\n\nThe output tells us Allen threw for 4,049 yards on 603 attempts during the 2021 regular season. A check of his Pro Football Reference page tells us those numbers are incorrect. In fact, he had 4,407 passing yards on 646 attempts. How did we end up 358 passing yards and 43 attempts short?\nThe answer comes from Aaron Schatz, the creator of Football Outsiders, who explained in a Tweet that the official Buffalo Bills’ scorer, during week 3 of the NFL season, decided to refer to Allen as “Jos.Allen” as a result of the Washington Commanders having a player named “Jonathan Allen.”\nTo double check this, we can run the same code as above, but remove the player_name filter and switch to searching for just those players on the Buffalo Bills by using recent_team.\n\ntwo.josh.allens <- weekly.data %>%\n  group_by(player_id, player_name) %>%\n  filter(season_type == \"REG\" & recent_team == \"BUF\") %>%\n  summarize(total.yards = sum(passing_yards),\n            n.attempts = sum(attempts))\n\ntibble(two.josh.allens)\n\n# A tibble: 16 x 4\n   player_id  player_name  total.yards n.attempts\n   <chr>      <chr>              <dbl>      <int>\n 1 00-0027685 E.Sanders              0          0\n 2 00-0029000 C.Beasley              0          1\n 3 00-0031588 S.Diggs                0          0\n 4 00-0031787 J.Kumerow              0          0\n 5 00-0033308 M.Breida               0          0\n 6 00-0033466 I.McKenzie             0          0\n 7 00-0033550 D.Webb                 0          0\n 8 00-0033869 M.Trubisky            43          8\n 9 00-0033904 D.Dawkins              0          0\n10 00-0034857 J.Allen             4407        646\n11 00-0035250 D.Singletary           0          0\n12 00-0035308 T.Sweeney              0          0\n13 00-0035689 D.Knox                 0          0\n14 00-0036187 R.Gilliam              0          0\n15 00-0036196 G.Davis                0          0\n16 00-0036251 Z.Moss                 0          0\n\n\nGrouping by player_id and player_name (as well as filtering down to Buffalo), we can see that, indeed, Josh Allen is in the data twice under the same player_id. Moreover, if you do the math, you can see that the numbers from his two entries add up to the official statistics on his Pro Football Reference page.\n\n4.1.1.1 Using load_player_stats() Correctly\nTo avoid these situations, you could load up NFL rosters via the nflreadr::load_rosters() function, but that would require unnecessary code in order to merge the two DFs together by matching the player_id to the gsis_id number found within the roster information. Doing so would correct the above issue of Josh Allen appearing in the data under different spellings. Instead, and to write the minimal amount of code to complete the task, we can do the following:\n\njosh.allen <- weekly.data %>%\n  filter(season_type == \"REG\") %>%\n  group_by(player_id) %>%\n  summarize(player_name = first(player_name),\n            total.yards = sum(passing_yards),\n            n.attempts = sum(attempts)) %>%\n  filter(player_name == \"J.Allen\")\n\nThe most efficient way to gather correct player statistics is to do the group_by with ONLY the player_id as, despite the variation in name, the player_id remained the same for Josh Allen. In order to include his correct name in the output, we can gather QB names within the summarize prior to calculating the sum of passing_yards and attempts. After, if you desire to see only Josh Allen’s number, you can filter out to just his name.\n\n4.1.2 Using load_player_stats() To Find Leaders\nWhile using load_player_stats() does not provide the ability to add context to your analysis as we will soon see with load_pbp(), it does provide an easy and efficient way to determine weekly or season-long leaders over many top-level, widely-used NFL statistics. In the below example, we will determine the 2021 leaders in air yards per attempt.\n\n4.1.2.1 An Example: 2021 QB Air Yards per Attempt Leaders\n\ndata <- nflreadr::load_player_stats(2021)\n\nay.per.attempt <- data %>%\n  group_by(player_id) %>%\n  filter(season_type == \"REG\") %>%\n  summarize(player_name = first(player_name),\n            n.attempts = sum(attempts),\n            n.airyards = sum(passing_air_yards),\n            ay.attempt = n.airyards / n.attempts) %>%\n  filter(n.attempts >= 400) %>%\n  select(player_name, ay.attempt) %>%\n  arrange(-ay.attempt)\n\nIn the above example, we are using group_by to combine the desired statistics based on each unique player_id to, again, avoid any issues with player names within the data. After filtering to include just those statistics for the regular season, we first use the summarize function to grab the first player_name associated with the player_id. After, we find two items: (1.) the total number of passing attempts by each QB which is outputted into a new row titled n.attempts and the regular season total of each QB’s air yards, again outputted into a new row titled n.airyards.\nIt is important to note that the final row created with the summarize function is not a statistic included within load_player_stats(). In order to find a QB’s average air yards per attempt, we must use the first two items we’ve created and do some simple division (the created n.airyards divided by n.attempts).\nFinally, to “clear the noise” of those QBs with minimal attempts through the season, we included a filter to include only those passers with at least 400 attempts. After, we arrange the new DF by sorting the QBs in descending order by average air yards per attempt.\nThe end results look like this:\n\n\n# A tibble: 25 x 2\n   player_name   ay.attempt\n   <chr>              <dbl>\n 1 R.Wilson            9.89\n 2 J.Hurts             8.99\n 3 B.Mayfield          8.73\n 4 M.Stafford          8.48\n 5 J.Allen             8.20\n 6 K.Cousins           8.16\n 7 J.Burrow            8.12\n 8 D.Carr              8.12\n 9 T.Brady             8.10\n10 T.Bridgewater       8.04\n# ... with 15 more rows\n\n\nRussell Wilson led the NFL in 2021 with 9.89 air yards per attempt."
  },
  {
    "objectID": "03-nfl-analytics-functions.html#using-load_pbp-to-add-context-to-statistics",
    "href": "03-nfl-analytics-functions.html#using-load_pbp-to-add-context-to-statistics",
    "title": "\n4  NFL Analytics with the nflverse Family of Packages\n",
    "section": "\n4.2 Using load_pbp() to Add Context to Statistics",
    "text": "4.2 Using load_pbp() to Add Context to Statistics\nAs just mentioned above, using the load_pbp() function is preferable when you are looking to add context to a player’s statistics, as the load_player_stats() function is, for all intents and purposes, aggregated statistics that limit your ability to find deeper meaning.\nThe load_pbp() function provides over 350 various metrics, as listed below:\n\npbp.data <- nflreadr::load_pbp(2021)\nls(pbp.data)\n\n  [1] \"aborted_play\"                        \n  [2] \"air_epa\"                             \n  [3] \"air_wpa\"                             \n  [4] \"air_yards\"                           \n  [5] \"assist_tackle\"                       \n  [6] \"assist_tackle_1_player_id\"           \n  [7] \"assist_tackle_1_player_name\"         \n  [8] \"assist_tackle_1_team\"                \n  [9] \"assist_tackle_2_player_id\"           \n [10] \"assist_tackle_2_player_name\"         \n [11] \"assist_tackle_2_team\"                \n [12] \"assist_tackle_3_player_id\"           \n [13] \"assist_tackle_3_player_name\"         \n [14] \"assist_tackle_3_team\"                \n [15] \"assist_tackle_4_player_id\"           \n [16] \"assist_tackle_4_player_name\"         \n [17] \"assist_tackle_4_team\"                \n [18] \"away_coach\"                          \n [19] \"away_score\"                          \n [20] \"away_team\"                           \n [21] \"away_timeouts_remaining\"             \n [22] \"away_wp\"                             \n [23] \"away_wp_post\"                        \n [24] \"blocked_player_id\"                   \n [25] \"blocked_player_name\"                 \n [26] \"comp_air_epa\"                        \n [27] \"comp_air_wpa\"                        \n [28] \"comp_yac_epa\"                        \n [29] \"comp_yac_wpa\"                        \n [30] \"complete_pass\"                       \n [31] \"cp\"                                  \n [32] \"cpoe\"                                \n [33] \"def_wp\"                              \n [34] \"defensive_extra_point_attempt\"       \n [35] \"defensive_extra_point_conv\"          \n [36] \"defensive_two_point_attempt\"         \n [37] \"defensive_two_point_conv\"            \n [38] \"defteam\"                             \n [39] \"defteam_score\"                       \n [40] \"defteam_score_post\"                  \n [41] \"defteam_timeouts_remaining\"          \n [42] \"desc\"                                \n [43] \"div_game\"                            \n [44] \"down\"                                \n [45] \"drive\"                               \n [46] \"drive_end_transition\"                \n [47] \"drive_end_yard_line\"                 \n [48] \"drive_ended_with_score\"              \n [49] \"drive_first_downs\"                   \n [50] \"drive_game_clock_end\"                \n [51] \"drive_game_clock_start\"              \n [52] \"drive_inside20\"                      \n [53] \"drive_play_count\"                    \n [54] \"drive_play_id_ended\"                 \n [55] \"drive_play_id_started\"               \n [56] \"drive_quarter_end\"                   \n [57] \"drive_quarter_start\"                 \n [58] \"drive_real_start_time\"               \n [59] \"drive_start_transition\"              \n [60] \"drive_start_yard_line\"               \n [61] \"drive_time_of_possession\"            \n [62] \"drive_yards_penalized\"               \n [63] \"end_clock_time\"                      \n [64] \"end_yard_line\"                       \n [65] \"ep\"                                  \n [66] \"epa\"                                 \n [67] \"extra_point_attempt\"                 \n [68] \"extra_point_prob\"                    \n [69] \"extra_point_result\"                  \n [70] \"fantasy\"                             \n [71] \"fantasy_id\"                          \n [72] \"fantasy_player_id\"                   \n [73] \"fantasy_player_name\"                 \n [74] \"fg_prob\"                             \n [75] \"field_goal_attempt\"                  \n [76] \"field_goal_result\"                   \n [77] \"first_down\"                          \n [78] \"first_down_pass\"                     \n [79] \"first_down_penalty\"                  \n [80] \"first_down_rush\"                     \n [81] \"fixed_drive\"                         \n [82] \"fixed_drive_result\"                  \n [83] \"forced_fumble_player_1_player_id\"    \n [84] \"forced_fumble_player_1_player_name\"  \n [85] \"forced_fumble_player_1_team\"         \n [86] \"forced_fumble_player_2_player_id\"    \n [87] \"forced_fumble_player_2_player_name\"  \n [88] \"forced_fumble_player_2_team\"         \n [89] \"fourth_down_converted\"               \n [90] \"fourth_down_failed\"                  \n [91] \"fumble\"                              \n [92] \"fumble_forced\"                       \n [93] \"fumble_lost\"                         \n [94] \"fumble_not_forced\"                   \n [95] \"fumble_out_of_bounds\"                \n [96] \"fumble_recovery_1_player_id\"         \n [97] \"fumble_recovery_1_player_name\"       \n [98] \"fumble_recovery_1_team\"              \n [99] \"fumble_recovery_1_yards\"             \n[100] \"fumble_recovery_2_player_id\"         \n[101] \"fumble_recovery_2_player_name\"       \n[102] \"fumble_recovery_2_team\"              \n[103] \"fumble_recovery_2_yards\"             \n[104] \"fumbled_1_player_id\"                 \n[105] \"fumbled_1_player_name\"               \n[106] \"fumbled_1_team\"                      \n[107] \"fumbled_2_player_id\"                 \n[108] \"fumbled_2_player_name\"               \n[109] \"fumbled_2_team\"                      \n[110] \"game_date\"                           \n[111] \"game_half\"                           \n[112] \"game_id\"                             \n[113] \"game_seconds_remaining\"              \n[114] \"game_stadium\"                        \n[115] \"goal_to_go\"                          \n[116] \"half_sack_1_player_id\"               \n[117] \"half_sack_1_player_name\"             \n[118] \"half_sack_2_player_id\"               \n[119] \"half_sack_2_player_name\"             \n[120] \"half_seconds_remaining\"              \n[121] \"home_coach\"                          \n[122] \"home_opening_kickoff\"                \n[123] \"home_score\"                          \n[124] \"home_team\"                           \n[125] \"home_timeouts_remaining\"             \n[126] \"home_wp\"                             \n[127] \"home_wp_post\"                        \n[128] \"id\"                                  \n[129] \"incomplete_pass\"                     \n[130] \"interception\"                        \n[131] \"interception_player_id\"              \n[132] \"interception_player_name\"            \n[133] \"jersey_number\"                       \n[134] \"kick_distance\"                       \n[135] \"kicker_player_id\"                    \n[136] \"kicker_player_name\"                  \n[137] \"kickoff_attempt\"                     \n[138] \"kickoff_downed\"                      \n[139] \"kickoff_fair_catch\"                  \n[140] \"kickoff_in_endzone\"                  \n[141] \"kickoff_inside_twenty\"               \n[142] \"kickoff_out_of_bounds\"               \n[143] \"kickoff_returner_player_id\"          \n[144] \"kickoff_returner_player_name\"        \n[145] \"lateral_interception_player_id\"      \n[146] \"lateral_interception_player_name\"    \n[147] \"lateral_kickoff_returner_player_id\"  \n[148] \"lateral_kickoff_returner_player_name\"\n[149] \"lateral_punt_returner_player_id\"     \n[150] \"lateral_punt_returner_player_name\"   \n[151] \"lateral_receiver_player_id\"          \n[152] \"lateral_receiver_player_name\"        \n[153] \"lateral_receiving_yards\"             \n[154] \"lateral_reception\"                   \n[155] \"lateral_recovery\"                    \n[156] \"lateral_return\"                      \n[157] \"lateral_rush\"                        \n[158] \"lateral_rusher_player_id\"            \n[159] \"lateral_rusher_player_name\"          \n[160] \"lateral_rushing_yards\"               \n[161] \"lateral_sack_player_id\"              \n[162] \"lateral_sack_player_name\"            \n[163] \"location\"                            \n[164] \"name\"                                \n[165] \"nfl_api_id\"                          \n[166] \"no_huddle\"                           \n[167] \"no_score_prob\"                       \n[168] \"old_game_id\"                         \n[169] \"opp_fg_prob\"                         \n[170] \"opp_safety_prob\"                     \n[171] \"opp_td_prob\"                         \n[172] \"order_sequence\"                      \n[173] \"out_of_bounds\"                       \n[174] \"own_kickoff_recovery\"                \n[175] \"own_kickoff_recovery_player_id\"      \n[176] \"own_kickoff_recovery_player_name\"    \n[177] \"own_kickoff_recovery_td\"             \n[178] \"pass\"                                \n[179] \"pass_attempt\"                        \n[180] \"pass_defense_1_player_id\"            \n[181] \"pass_defense_1_player_name\"          \n[182] \"pass_defense_2_player_id\"            \n[183] \"pass_defense_2_player_name\"          \n[184] \"pass_length\"                         \n[185] \"pass_location\"                       \n[186] \"pass_oe\"                             \n[187] \"pass_touchdown\"                      \n[188] \"passer\"                              \n[189] \"passer_id\"                           \n[190] \"passer_jersey_number\"                \n[191] \"passer_player_id\"                    \n[192] \"passer_player_name\"                  \n[193] \"passing_yards\"                       \n[194] \"penalty\"                             \n[195] \"penalty_player_id\"                   \n[196] \"penalty_player_name\"                 \n[197] \"penalty_team\"                        \n[198] \"penalty_type\"                        \n[199] \"penalty_yards\"                       \n[200] \"play\"                                \n[201] \"play_clock\"                          \n[202] \"play_deleted\"                        \n[203] \"play_id\"                             \n[204] \"play_type\"                           \n[205] \"play_type_nfl\"                       \n[206] \"posteam\"                             \n[207] \"posteam_score\"                       \n[208] \"posteam_score_post\"                  \n[209] \"posteam_timeouts_remaining\"          \n[210] \"posteam_type\"                        \n[211] \"punt_attempt\"                        \n[212] \"punt_blocked\"                        \n[213] \"punt_downed\"                         \n[214] \"punt_fair_catch\"                     \n[215] \"punt_in_endzone\"                     \n[216] \"punt_inside_twenty\"                  \n[217] \"punt_out_of_bounds\"                  \n[218] \"punt_returner_player_id\"             \n[219] \"punt_returner_player_name\"           \n[220] \"punter_player_id\"                    \n[221] \"punter_player_name\"                  \n[222] \"qb_dropback\"                         \n[223] \"qb_epa\"                              \n[224] \"qb_hit\"                              \n[225] \"qb_hit_1_player_id\"                  \n[226] \"qb_hit_1_player_name\"                \n[227] \"qb_hit_2_player_id\"                  \n[228] \"qb_hit_2_player_name\"                \n[229] \"qb_kneel\"                            \n[230] \"qb_scramble\"                         \n[231] \"qb_spike\"                            \n[232] \"qtr\"                                 \n[233] \"quarter_end\"                         \n[234] \"quarter_seconds_remaining\"           \n[235] \"receiver\"                            \n[236] \"receiver_id\"                         \n[237] \"receiver_jersey_number\"              \n[238] \"receiver_player_id\"                  \n[239] \"receiver_player_name\"                \n[240] \"receiving_yards\"                     \n[241] \"replay_or_challenge\"                 \n[242] \"replay_or_challenge_result\"          \n[243] \"result\"                              \n[244] \"return_team\"                         \n[245] \"return_touchdown\"                    \n[246] \"return_yards\"                        \n[247] \"roof\"                                \n[248] \"run_gap\"                             \n[249] \"run_location\"                        \n[250] \"rush\"                                \n[251] \"rush_attempt\"                        \n[252] \"rush_touchdown\"                      \n[253] \"rusher\"                              \n[254] \"rusher_id\"                           \n[255] \"rusher_jersey_number\"                \n[256] \"rusher_player_id\"                    \n[257] \"rusher_player_name\"                  \n[258] \"rushing_yards\"                       \n[259] \"sack\"                                \n[260] \"sack_player_id\"                      \n[261] \"sack_player_name\"                    \n[262] \"safety\"                              \n[263] \"safety_player_id\"                    \n[264] \"safety_player_name\"                  \n[265] \"safety_prob\"                         \n[266] \"score_differential\"                  \n[267] \"score_differential_post\"             \n[268] \"season\"                              \n[269] \"season_type\"                         \n[270] \"series\"                              \n[271] \"series_result\"                       \n[272] \"series_success\"                      \n[273] \"shotgun\"                             \n[274] \"side_of_field\"                       \n[275] \"solo_tackle\"                         \n[276] \"solo_tackle_1_player_id\"             \n[277] \"solo_tackle_1_player_name\"           \n[278] \"solo_tackle_1_team\"                  \n[279] \"solo_tackle_2_player_id\"             \n[280] \"solo_tackle_2_player_name\"           \n[281] \"solo_tackle_2_team\"                  \n[282] \"sp\"                                  \n[283] \"special\"                             \n[284] \"special_teams_play\"                  \n[285] \"spread_line\"                         \n[286] \"st_play_type\"                        \n[287] \"stadium\"                             \n[288] \"stadium_id\"                          \n[289] \"start_time\"                          \n[290] \"success\"                             \n[291] \"surface\"                             \n[292] \"tackle_for_loss_1_player_id\"         \n[293] \"tackle_for_loss_1_player_name\"       \n[294] \"tackle_for_loss_2_player_id\"         \n[295] \"tackle_for_loss_2_player_name\"       \n[296] \"tackle_with_assist\"                  \n[297] \"tackle_with_assist_1_player_id\"      \n[298] \"tackle_with_assist_1_player_name\"    \n[299] \"tackle_with_assist_1_team\"           \n[300] \"tackle_with_assist_2_player_id\"      \n[301] \"tackle_with_assist_2_player_name\"    \n[302] \"tackle_with_assist_2_team\"           \n[303] \"tackled_for_loss\"                    \n[304] \"td_player_id\"                        \n[305] \"td_player_name\"                      \n[306] \"td_prob\"                             \n[307] \"td_team\"                             \n[308] \"temp\"                                \n[309] \"third_down_converted\"                \n[310] \"third_down_failed\"                   \n[311] \"time\"                                \n[312] \"time_of_day\"                         \n[313] \"timeout\"                             \n[314] \"timeout_team\"                        \n[315] \"total\"                               \n[316] \"total_away_comp_air_epa\"             \n[317] \"total_away_comp_air_wpa\"             \n[318] \"total_away_comp_yac_epa\"             \n[319] \"total_away_comp_yac_wpa\"             \n[320] \"total_away_epa\"                      \n[321] \"total_away_pass_epa\"                 \n[322] \"total_away_pass_wpa\"                 \n[323] \"total_away_raw_air_epa\"              \n[324] \"total_away_raw_air_wpa\"              \n[325] \"total_away_raw_yac_epa\"              \n[326] \"total_away_raw_yac_wpa\"              \n[327] \"total_away_rush_epa\"                 \n[328] \"total_away_rush_wpa\"                 \n[329] \"total_away_score\"                    \n[330] \"total_home_comp_air_epa\"             \n[331] \"total_home_comp_air_wpa\"             \n[332] \"total_home_comp_yac_epa\"             \n[333] \"total_home_comp_yac_wpa\"             \n[334] \"total_home_epa\"                      \n[335] \"total_home_pass_epa\"                 \n[336] \"total_home_pass_wpa\"                 \n[337] \"total_home_raw_air_epa\"              \n[338] \"total_home_raw_air_wpa\"              \n[339] \"total_home_raw_yac_epa\"              \n[340] \"total_home_raw_yac_wpa\"              \n[341] \"total_home_rush_epa\"                 \n[342] \"total_home_rush_wpa\"                 \n[343] \"total_home_score\"                    \n[344] \"total_line\"                          \n[345] \"touchback\"                           \n[346] \"touchdown\"                           \n[347] \"two_point_attempt\"                   \n[348] \"two_point_conv_result\"               \n[349] \"two_point_conversion_prob\"           \n[350] \"vegas_home_wp\"                       \n[351] \"vegas_home_wpa\"                      \n[352] \"vegas_wp\"                            \n[353] \"vegas_wpa\"                           \n[354] \"weather\"                             \n[355] \"week\"                                \n[356] \"wind\"                                \n[357] \"wp\"                                  \n[358] \"wpa\"                                 \n[359] \"xpass\"                               \n[360] \"xyac_epa\"                            \n[361] \"xyac_fd\"                             \n[362] \"xyac_mean_yardage\"                   \n[363] \"xyac_median_yardage\"                 \n[364] \"xyac_success\"                        \n[365] \"yac_epa\"                             \n[366] \"yac_wpa\"                             \n[367] \"yardline_100\"                        \n[368] \"yards_after_catch\"                   \n[369] \"yards_gained\"                        \n[370] \"ydsnet\"                              \n[371] \"ydstogo\"                             \n[372] \"yrdln\"                               \n\n\nA bit overwhelming, right?\nLuckily, the nflfastR website includes a searchable directory of all the variables with a brief description of what each one means. You can visit that here: nflfastR Field Descriptions.\nAs seen above, we can use the load_player_stats() function to determine a QB’s average yards per attempt over the course of a season. But, what if we wanted to add context to that? For example, how do we explore a QB’s air yards in game-specific situations?\nTo showcase using load_pbp() to add context to your analysis, let’s explore QB performance via air yards on 3rd down.\n\n4.2.1 An Example: QB Aggressiveness on 3rd Down\nSticking with the air yards example from above, let’s examine a metric I created using load_pbp() that I coined QB 3rd Down Aggressiveness. The metric is designed to determine which QBs in the NFL are most aggressive in 3rd down situations by gauging how often they throw the ball to, or pass, the first down line. It is an interesting metric to explore as, just like many metrics in the NFL, not all air yards are created equal. For example, eight air yards on 1st and 10 are less valuable than the same eight air yards on 3rd and 5.\nFirst, let’s highlight the code used to create the results for this metric and then break it down line-by-line.\n\ndata <- nflreadr::load_pbp(2021)\n\naggressiveness <- data %>%\n  group_by(passer_id) %>%\n  filter(down == 3, play_type == \"pass\", ydstogo >= 5, ydstogo <= 10) %>%\n  summarize(player_name = first(passer),\n            team = first(posteam),\n            total = n(),\n            aggressive = sum(air_yards >= ydstogo, na.rm = TRUE),\n            percentage = aggressive / total) %>%\n  filter(total >= 50) %>%\n  arrange(-percentage)\n\ntibble(aggressiveness)\n\n# A tibble: 30 x 6\n   passer_id  player_name  team  total aggressive percentage\n   <chr>      <chr>        <chr> <int>      <int>      <dbl>\n 1 00-0033077 D.Prescott   DAL      84         53      0.631\n 2 00-0035228 K.Murray     ARI      60         37      0.617\n 3 00-0036389 J.Hurts      PHI      65         40      0.615\n 4 00-0033873 P.Mahomes    KC       93         56      0.602\n 5 00-0034855 B.Mayfield   CLE      59         35      0.593\n 6 00-0036971 T.Lawrence   JAX      78         46      0.590\n 7 00-0036355 J.Herbert    LAC      87         51      0.586\n 8 00-0035710 D.Jones      NYG      60         35      0.583\n 9 00-0036212 T.Tagovailoa MIA      60         35      0.583\n10 00-0026498 M.Stafford   LA       95         54      0.568\n# ... with 20 more rows\n\n\nAs you can see in the tibble() output of the results, Dak Prescott was the most aggressive quarterback in 3rd down passing situations in the 2021 season, passing to, our beyond, the line of gain just over 63% of the time.\nAfter creating a new dataframe called aggressiveness from the 2021 play-by-play we originally collected using data <- nflreadr::load_pbp(2021), we use group_by to ensure that the data is being collected per individual quarterback via passer_id.\nAfter using the group_by function to lump data with each individual QB, we then use filter() function. Of course, we only want those play_types that are “pass” on 3rd downs. However, in the above code, we are filtering for just those 3rd down situations where the yards to go are between five and ten yards.\nDoing so was a personal decision on my end when creating the metric, as there are certainly arguments to be made regarding how to “capture” scenarios in the data that require “aggressiveness.” My logic? If there were less than five yards to go on 3rd down, the opposing defense would not be able to “sell out” to the pass as it would not be out of the question for an offense to attempt to gain the first down on the ground. Conversely, anything over ten yards likely results in the defense selling out to the pass, thus leaving an imprint on the aggressiveness output of the quarterbacks.\nFor the sake of curiosity, we can edit the above code to include all passing attempts on 3rd down with under 10 yards to go for the first down:\n\naggressiveness.under.10 <- data %>%\n  group_by(passer_id) %>%\n  filter(down == 3, play_type == \"pass\", ydstogo <= 10) %>%\n  summarize(player_name = first(passer),\n            team = first(posteam),\n            total = n(),\n            aggressive = sum(air_yards >= ydstogo, na.rm = TRUE),\n            percentage = aggressive / total) %>%\n  filter(total >= 50) %>%\n  arrange(desc(percentage))\n\ntibble(aggressiveness.under.10)\n\n# A tibble: 33 x 6\n   passer_id  player_name  team  total aggressive percentage\n   <chr>      <chr>        <chr> <int>      <int>      <dbl>\n 1 00-0035228 K.Murray     ARI      98         67      0.684\n 2 00-0036389 J.Hurts      PHI     107         73      0.682\n 3 00-0036971 T.Lawrence   JAX     131         88      0.672\n 4 00-0033077 D.Prescott   DAL     136         89      0.654\n 5 00-0034857 J.Allen      BUF     138         88      0.638\n 6 00-0036355 J.Herbert    LAC     148         94      0.635\n 7 00-0036212 T.Tagovailoa MIA      93         59      0.634\n 8 00-0026498 M.Stafford   LA      172        109      0.634\n 9 00-0023459 A.Rodgers    GB      128         80      0.625\n10 00-0035710 D.Jones      NYG      85         53      0.624\n# ... with 23 more rows\n\n\nThe results are quite different from the first running of this metric, as Dak Prescott is now the 4th most aggressive QB, while Kyler Murray moves to the top by approaching a nearly 70% aggressiveness rate on 3rd down. This small change highlights an important element about analytics: much of the work is the result of the coder (ie., you) being able to justify your decision-making process when developing the filters for each metric you create.\nIn this case, I stand by my argument that including just those pass attempts on 3rd down with between 5 and 10 yards to go is a more accurate assessment of aggressiveness as, for example, 3rd down with 8 yards to go is an obvious passing situation in most cases.\nThat begs the question, though: in which cases is 3rd down with 8 yards to go not an obvious passing situation? An example of this falls under the guise of “garbage time.”\n\n4.2.1.1 QB Aggressiveness: Filtering for “Garbage Time?”\nIn our initial running of the QB Aggressiveness metric, Josh Allen is the 15th most aggressive QB in the NFL on 3rd down with between 5 and 10 yards to go. But how much does the success of the Buffalo Bills play into that 15th place ranking?\nThe Bills, at the conclusion of the 2021 season, had the largest positive point differential in the league at 194 (the Bills scored 483 points, while allowing just 289). Perhaps Allen’s numbers are skewed because the Bills were so often playing with the lead late into the game?\nTo account for this, we can add information into the filter() function to attempt to remove what are referenced to in the analytics community as “garbage time stats.”\nLet’s add the “garbage time” filter to the code we’ve already prepared:\n\naggressiveness.garbage <- data %>%\n  group_by(passer_id) %>%\n  filter(down == 3, play_type == \"pass\", ydstogo >= 5, ydstogo <= 10,\n         wp > .05, wp < .95, half_seconds_remaining > 120) %>%\n  summarize(player_name = first(passer),\n            team = first(posteam),\n            total = n(),\n            aggressive = sum(air_yards >= ydstogo, na.rm = TRUE),\n            percentage = aggressive / total) %>%\n  filter(total >= 50) %>%\n  arrange(desc(percentage))\n\ntibble(aggressiveness.garbage)\n\n# A tibble: 26 x 6\n   passer_id  player_name team  total aggressive percentage\n   <chr>      <chr>       <chr> <int>      <int>      <dbl>\n 1 00-0033077 D.Prescott  DAL      61         40      0.656\n 2 00-0036971 T.Lawrence  JAX      51         33      0.647\n 3 00-0035228 K.Murray    ARI      51         31      0.608\n 4 00-0026498 M.Stafford  LA       79         48      0.608\n 5 00-0033873 P.Mahomes   KC       68         41      0.603\n 6 00-0035710 D.Jones     NYG      50         30      0.6  \n 7 00-0036355 J.Herbert   LAC      67         38      0.567\n 8 00-0036972 M.Jones     NE       57         31      0.544\n 9 00-0034857 J.Allen     BUF      59         32      0.542\n10 00-0029263 R.Wilson    SEA      56         30      0.536\n# ... with 16 more rows\n\n\nWe are now using the same code, but have included three new items to the filter(). First, we are stipulating that, aside from the down and distance inclusion, we only want those plays that occurred when the offense’s win probability was between 5% and 95%, as well as ensuring that the plays did not happen after the two-minute warning of either half.\nThe decision on range of the win probability numbers is, again, a personal preference. When nflfastR was first released, analyst often used a 20-80% range for win probability. However, Sebastian Carl - one of the creators of the nflverse explained in the package’s Discord:\n\nSebastian Carl: “I am generally very conservative with filtering plays using wp. Especially the vegas wp model can reach >85% probs early in the game because it incorporates market lines. I never understood the 20% <= wp <= 80%”garbage time” filter. This is removing a ton of plays. My general advice is a lower boundary of something around 5% (i.e., 5% <= wp <= 95%).\n\nBen Baldwin followed up on Carl’s thoughts:\n\nBen Baldwin: “agree with this. 20-80% should only be used as a filter for looking at how run-heavy a team is (because outside of this range is when teams change behavior a lot). and possibly how teams behave on 4th downs. but not for team or player performance.”\n\nBased on that advice, I typically stick to the 5-95% range when filtering for win probability using play-by-play data. And, in this case, it did have an impact.\nAs mentioned, prior to filtering for garbage time, Allen was the 15th most aggressive QB in the league at nearly 52%. However, once filtering for garbage time, Allen rose to 9th most aggressive QB, with a slight increase of percentage to 54%.\nWhat is interesting about the above example, though, is Dak Prescott and the Cowboys. Dallas maintained the second largest point differential in the league (530 points for and 358 points against, for a 172 point difference). Without the garbage time filter, Prescott was tops in the NFL with an aggressiveness rating of 63%.\nOnce adjusted for garbage time? Prescott remained atop the NFL with an aggressiveness rating of 65.5%.\nAllen’s increase in the standings, and Prescott remaining best in the league, in this specific metric, is a possible indicator that the inclusion of the “garbage time” filters provides a slightly more accurate result.\n\n4.2.2 The Inclusion of Contextual Statistics\nAs seen in the above example regarding QB aggressiveness on 3rd down, the using of the load_pbp() function provides the ability to create situation specific metrics that would otherwise be lost in aggregated weekly statistics."
  },
  {
    "objectID": "03-nfl-analytics-functions.html#retrieving-working-with-data-for-multiple-seasons",
    "href": "03-nfl-analytics-functions.html#retrieving-working-with-data-for-multiple-seasons",
    "title": "\n4  NFL Analytics with the nflverse Family of Packages\n",
    "section": "\n4.3 Retrieving & Working With Data for Multiple Seasons",
    "text": "4.3 Retrieving & Working With Data for Multiple Seasons\nIn the case of both load_pbp() and load_player_stats(), it is possible to load data over multiple seasons.\nIn our above example calculating average air yard per attempt, it is important to note that Russell Wilson’s league-leading average of 9.89 air yards per attempt is calculated using all passing attempts, meaning pass attempts that were both complete and incomplete.\nIn our first example of working with data across multiple seasons, let’s examine average air yards for only completed passes. To begin, we will retrieve the play-by-play data for the last five seasons:\n\nay.five.years <- nflreadr::load_pbp(2017:2021)\n\nTo retrieve multiple seasons of data, a colon : is placed between the years that you want. When you run the code, nflreadr will output the data to include the play-by-play data starting with the oldest season (in this case, the 2017 NFL season).\nOnce you have the data collected, we can run code that looks quite similar to our code above that explored 2021’s air yards per attempt leaders using load_player_stats(). In this case, however, we are including an additional filter to gather those passing attempts that resulted only in complete passes:\n\naverage.airyards <- ay.five.years %>%\n  group_by(passer_id) %>%\n  filter(season_type == \"REG\" & complete_pass == 1) %>%\n  summarize(player = first(passer_player_name),\n            completions = sum(complete_pass),\n            air.yards = sum(air_yards),\n            average = air.yards / completions) %>%\n  filter(completions >= 1000) %>%\n  arrange(-average)\n\ntibble(average.airyards)\n\n# A tibble: 22 x 5\n   passer_id  player      completions air.yards average\n   <chr>      <chr>             <dbl>     <dbl>   <dbl>\n 1 00-0031503 J.Winston          1008      8174    8.11\n 2 00-0033537 D.Watson           1186      8461    7.13\n 3 00-0029263 R.Wilson           1603     10939    6.82\n 4 00-0026143 M.Ryan             1954     13051    6.68\n 5 00-0034855 B.Mayfield         1185      7858    6.63\n 6 00-0034857 J.Allen            1245      8221    6.60\n 7 00-0033077 D.Prescott         1613     10449    6.48\n 8 00-0026498 M.Stafford         1668     10804    6.48\n 9 00-0029701 R.Tannehill        1049      6680    6.37\n10 00-0032950 C.Wentz            1505      9491    6.31\n# ... with 12 more rows\n\n\nOf those QBs with at least 1,000 complete passes since the 2017 season, Jameis Winston has the highest average air yards per complete pass at 8.11."
  },
  {
    "objectID": "03-nfl-analytics-functions.html#working-with-the-various-nflverse-functions",
    "href": "03-nfl-analytics-functions.html#working-with-the-various-nflverse-functions",
    "title": "\n4  NFL Analytics with the nflverse Family of Packages\n",
    "section": "\n4.4 Working with the Various nflverse Functions",
    "text": "4.4 Working with the Various nflverse Functions"
  },
  {
    "objectID": "04-nfl-analytics-visualization.html#data-viz-must-understand-the-audience",
    "href": "04-nfl-analytics-visualization.html#data-viz-must-understand-the-audience",
    "title": "\n5  Data Visualization with NFL Analytics\n",
    "section": "\n5.1 Data Viz Must Understand the Audience",
    "text": "5.1 Data Viz Must Understand the Audience\nAs explained by Stikeleather, the core purpose of a data visualization is to take “great quantities of information” and then convey that information in such a way that it is “easily assimilated by the consumers of the information.” In other words, the process of data visualization should allow for a great quantity of data to be distilled into an easily consumable (and understandable!) format.\nSpeaking specifically to NFL analytics, when doing visualizations we must be conscious about whether or not the intended audience will understand the terminology and concepts we use in the plot. For example, most all NFL fans understand the “non-advanced” statistics in the sport. But, when plots start using metrics such as EPA or completion percentage over expected, for example, the audience looking at the plot may very well have little understanding of what is being conveyed.\nBecause of this, any data viz I create never fails to include “directables” within the plot. These “directables” may be arrows that indicate which trend on the plot are “good” or they can be text within a scatterplot that explains what each quadrant means. Or, for example, I sometimes include a textual explanation of the “equation” used to develop a metric as seen below:\n\n\n\n\n\nThe above plot explores which QBs, from the 2020 season, were most aggressive on 3rd down with between 5 to 10 yards to go. Since “aggressiveness” is not a typical, day-to-day metric discussed by NFL fans, I included a “directable” within the subtitle of the plot that explained that the plot, first, was examining just 3rd down pass attempts within a specific yard range. And, second, I made the decision to include how “aggressiveness” was calculated by including the simple equation within the subtitle as well. Doing so allows even the most casual of NFL fans to easily understand what the plot is showing - in this case, that Joe Burrow’s 3rd down pass attempts with between 5 to 10 yards to go made it to the line of gain, or more, on 68% of his attempts. On the other hand, Drew Lock and Drew Brees were the least aggressive QBs in the line based on the same metric.\nAs another example, below is what I deemed my “Uncle Rico Metric” (because who does not like a good Napoleon Dynamite reference?):"
  },
  {
    "objectID": "04-nfl-analytics-visualization.html#setting-up-for-data-viz",
    "href": "04-nfl-analytics-visualization.html#setting-up-for-data-viz",
    "title": "\n5  Data Visualization with NFL Analytics\n",
    "section": "\n5.2 Setting Up for Data Viz",
    "text": "5.2 Setting Up for Data Viz\nWhile most of your journey through NFL analytics in this book required you to use the tidyverse and a handful of other packages, the process of creating compelling and meaningful data visualizations will require you to utilize multitudes of other packages. Of course, the most important is ggplot2 which is already installed via the tidyverse. However, in order to recreate the visualizations included in this chapter, it is required that you install other R packages. To install the necessary packages, you can run the following code in RStudio:"
  },
  {
    "objectID": "04-nfl-analytics-visualization.html#selecting-the-correct-type-of-plot",
    "href": "04-nfl-analytics-visualization.html#selecting-the-correct-type-of-plot",
    "title": "\n5  Data Visualization with NFL Analytics\n",
    "section": "\n5.3 Selecting The Correct Type of Plot",
    "text": "5.3 Selecting The Correct Type of Plot\n\n\n\n\nStikeleather, Jim. 2013. “The Three Elements of Successful Data Visualizations.” https://hbr.org/2013/04/the-three-elements-of-successf."
  },
  {
    "objectID": "05-nfl-analytics-advanced-methods.html",
    "href": "05-nfl-analytics-advanced-methods.html",
    "title": "\n6  Advanced Methods: Modeling and Big Data Bowl\n",
    "section": "",
    "text": "lots of place holding for Big Data Bowl material below\nThomas Bliss, a Data Scientist with the NFL, provided an incredibly helpful list of potential topics that can be explored using 2023 Big Data Bowl information:\n\nanalyze blocker positioning after the QB leaves the pocket and/or is pressured\nanalyze blocker ability to hold a defender in place without moving towards the QB\nlink the rate of false starts to an offensive line’s time off the snap\nlink between QB release time, receiver separation, and offensive line performance\n\n\n### reading all weeks and writing to a parquet file\nall_bdb_weeks <- function(dir = file.path('core-data')) {\n  paths <- fs::dir_ls(dir, regexp = 'week\\\\d+')\n  all_weeks <-\n    paths %>%\n    purrr::map_df(vroom::vroom) %>%\n    janitor::clean_names() %>%\n    arrow::write_parquet(file.path('core-data', 'data.parquet'))\n}\n\nall_bdb_weeks()\n\n### reading in all play information provided and writing to a parquet file\nread_bdb_plays <- memoise::memoise({function() {\n  plays <- file.path('core-data', 'plays.csv') %>%\n    readr::read_csv() %>%\n    janitor::clean_names() %>%\n    arrow::write_parquet(file.path('core-data', 'plays.parquet'))\n}})\n\nread_bdb_plays()\n\n### reading in individual game information and writing to a parquet file\nread_game_info <- memoise::memoise({function() {\n  file.path('core-data', 'games.csv') %>%\n    readr::read_csv() %>%\n    janitor::clean_names() %>%\n    dplyr::mutate(dplyr::across(game_date = lubridate::mdy)) %>%\n    arrow::write_parquet(file.path('core-data', 'games.parquet'))\n}})\n\n### creating an individual .cvs file for each game in bdb\nall.weeks <- read_parquet(\"./core-data/large-lfs-files/all-weeks-parquet\")\n\nall.weeks %>%\n  group_by(game_id) %>%\n  group_walk(~ write_csv(.x, paste0('tracking_gameId_', .y$game_id, \".csv\")))\n\n### writing in team colors, logos\nteam.colors <- nflfastR::teams_colors_logos %>%\n  select(team_abbr, team_color, team_color2, team_logo_espn)\n\nfffff\n\nrotate_the_dots <- function(df) {\n  \n  if(!\"play_direction\" %in% names(df)) {\n    message(\"Cannot find play directions. Inferring from offense and defense locations at snap.\")\n    \n    df <- df %>%\n      filter(event == \"ball_snap\", team != \"football\") %>%\n      group_by(game_id, play_id, defensive_team) %>%\n      summarize(mean_x = mean(x, na.rm = T)) %>%\n      pivot_wider(names_from = defensive_team, values_from = mean_x, names_prefix = \"x_\") %>%\n      ungroup() %>%\n      mutate(\n        play_direction = \n          ifelse(\n            x_1 > x_0,\n            \"right\",\n            \"left\") %>%\n          select(game_id, play_id, play_direction) %>%\n          inner_join(df, by = c(\"game_id\", \"play_id\")))\n        \n  }\n  \n  df <- df %>%\n    mutate(\n      to_left = ifelse(play_direction == \"left\", 1, 0),\n      x = ifelse(to_left == 1, 120 - x, x),\n      y = ifelse(to_left == 1, 160 / 3 - y, y),\n      los_x = 100 - absolute_yardline_number,\n      dist_from_los = x - los_x)\n  \n  if (\"o\" %in% names(df)) {\n    df <- df %>%\n      mutate(\n        o = ifelse(to_left == 1, o + 180, o),\n        o = ifelse(o > 360, 0 - 360, o),\n        o_rad = pi * (o / 180),\n        o_x = ifelse(is.na(o), NA_real_, sin(o_rad)),\n        o_y = ifelse(is.na(o), NA_real_, cos(o_rad)))\n  }\n  \n  if (\"dir\" %in% names(df)) {\n    df <- df %>%\n      mutate(\n        dir = ifelse(to_left == 1, dir + 180, dir),\n        dir = ifelse(dir > 360, dir - 360, dir),\n        dir_rad = pi * (dir / 180),\n        dir_x = ifelse(is.na(dir), NA_real_, sin(dir_rad)),\n        dir_y = ifelse(is.na(dir), NA_real_, cos(dir_rad)),\n        s_x = dir_x * s,\n        s_y = dir_y * s,\n        a_x = dir_x * a,\n        a_y = dir_y * a)\n  }\n  \n  return(df)\n}\n\nffff\n\nfind_o_diff <- function(df, prefix = \"qb\") {\n  \n  name_x <- sym(paste0(prefix, \"_x\"))\n  name_y <- sym(paste0(prefix, \"_y\"))\n  \n  new_column <- paste0(\"o_to_\", prefix)\n  \n  df <- df %>%\n    mutate(\n      dis_x = {{name_x}} - x,\n      dis_y = {{name_y}} - y,\n      \n      tmp = atan2(dis_y, dis_x) * (180 / pi),\n      tmp = (360 - tmp) + 90,\n      tmp = case_when(tmp < 0 ~ tmp + 360,\n                      tmp > 360 ~ tmp - 360,\n                      TRUE ~ tmp),\n      \n      diff = abs(o - tmp),\n      \n      diff = abs(o - tmp),\n      \n      !!new_column := pmin(360 - diff, diff)) %>%\n        select(-diff, -tmp)\n      \n    return(df)\n}\n\n\n########\n## READING IN PITTSBURGH VS. BUFFALO - WEEK 1\n########\n\npitt.buff <- arrow::read_parquet(\"core-data/large-lfs-files/all-weeks-parquet\") %>%\n  filter(game_id == \"2021091201\")\n\n########\n## READING IN PLAYS FROM PITTSBURGH VS. BUFFALO - WEEK 1\n########\n\npitt.buff.plays <- readr::read_csv(\"core-data/plays.csv\") %>%\n  janitor::clean_names() %>%\n  filter(game_id == \"2021091201\")\n\n########\n## READING IN GAME INFO FROM PITTSBURGH VS. BUFFALO - WEEK 1\n########\n\npitt.buff.info <- readr::read_csv(\"core-data/games.csv\") %>%\n  janitor::clean_names() %>%\n  filter(game_id == \"2021091201\")\n\n########\n## COMBING CORE GAME FILE WITH PLAYS, AND THEN BY INFO (TO AVOID MULTIPLE GAME_IDs IN DF)\n########\n\ncomplete.data <- inner_join(pitt.buff, pitt.buff.plays, by = c(\"game_id\" = \"game_id\", \"play_id\" = \"play_id\"))\n\ncomplete.data <- complete.data %>%\n  inner_join(pitt.buff.info, by = c(\"game_id\" = \"game_id\"))\n\n### ROTATING THE DOTS\ncomplete.data <- rotate_the_dots(complete.data)\n\n########\n## MUTATING TO CHARACTER VARIABLE DEFINING WHETHER TEAM IN FRAMES IS ON OFFENSE OR DEFENSE\n########\n\ncomplete.data <- complete.data %>%\n  mutate(off_or_def = case_when(\n    team == possession_team ~ \"offense\",\n    team != possession_team ~ \"defense\",\n    TRUE ~ \"football\"))\n\n            ########\n            ## CORE CLEANING AND PREP IS COMPLETE\n            ########\n\n########\n## ADDING IN INFORMATION FROM PLAYERS.CSV TO BUILD CHULLs FOR JUST O-LINE\n########\n\nplayer.info <- readr::read_csv(\"core-data/players.csv\") %>%\n  janitor::clean_names() %>%\n  select(nfl_id, official_position, display_name)\n\ncomplete.data <- complete.data %>%\n  inner_join(player.info, by = c(\"nfl_id\" = \"nfl_id\"))\n\n########\n## LET'S PICK OUT A FUN PLAY TO WORK WITH\n########\n\none.play <- complete.data %>%  ### BEN PASS TO EBRON FOR 19 YARDS\n  filter(play_id == 2209)\n\n########\n## NOW LET'S BUILD A CONVEX HULL FOR JUST THE OFFENSIVE LINE\n########\n\nol_chull_order <- one.play %>%\n  filter(off_or_def == \"offense\") %>%\n  filter(official_position %in% c(\"T\", \"C\", \"G\")) %>%  #### IMPORTANT TO KNOW PERSONNEL PACKAGE HERE: 0 RB, 0 TE, 5 WR\n  select(frame_id, x, y) %>%\n  chull\n\nol_chull_order <- c(ol_chull_order, ol_chull_order[1])\n\nol_chull_coords <- one.play %>%\n  filter(off_or_def == \"offense\") %>%\n  select(frame_id, x, y) %>%\n  slice(ol_chull_order)\n\nol_chull_poly <- sp::Polygon(ol_chull_coords, hole = F)\nol_chull_area <- ol_chull_poly@area\n\n########\n## NOW LET'S PLOT IT\n########\n\none.play %>%\n  the_dots(\n    animated = TRUE,\n    orientation = FALSE,\n    convex = TRUE,\n    segment_length = 6,\n    segment_size = 3,\n    dot_size = 4,\n    animated_h = 4,\n    animated_w = 8,\n    animated_res = 150\n  )"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Awbrey, Jake. 2020. “The Future of NFL Analytics.” https://www.samford.edu/sports-analytics/fans/2020/The-Future-of-NFL-Data-Analytics.\n\n\nBechtold, Taylor. 2021. “How the Analytics Movement Has Changed\nthe NFL and Where It Has Fallen Short.” https://theanalyst.com/na/2021/04/evolution-of-the-analytics-movement-in-the-nfl/.\n\n\n“Big Data Bowl: The Annual Analytics Contest Explores Statistical\nInnovations in Football.” n.d. https://operations.nfl.com/gameday/analytics/big-data-bowl/.\n\n\nBushnell, Henry. 2021. “NFL Teams Are Taking 4th-down Risks More\nThan Ever - but Still Not Often Enough.” https://sports.yahoo.com/nfl-teams-are-taking-4th-down-risks-more-than-ever-but-still-not-often-enough-163650973.html.\n\n\nCarl, Sebastian. 2022. “nflplotR.” https://nflplotr.nflverse.com/.\n\n\nFortier, Sam. 2020. “The NFL’s Analytics Movement Has Finally\nReached the Sport’s Mainstream.” https://www.washingtonpost.com/sports/2020/01/16/nfls-analytics-movement-has-finally-reached-sports-mainstream/.\n\n\nHeifetz, Danney. 2019. “We Salute You, Founding Father of the\nNFL’s Analytics Movement.” https://www.theringer.com/nfl-preview/2019/8/15/20806241/nfl-analytics-pro-football-focus.\n\n\nKirschner, Alex. 2022. “The Rams’ Super Bowl Afterparty Turned\ninto a Historic Hangover.” https://fivethirtyeight.com/features/the-rams-super-bowl-afterparty-turned-into-a-historic-hangover/.\n\n\nKozora, Alex. 2015. “Tomlin Prefers \"Feel over Analytics\".”\nhttp://steelersdepot.com/2015/09/tomlin-prefers-feel-over-analytics/.\n\n\nRosenthal, Gregg. 2018. “Super Bowl LII: How the 2017 Philadelphia\nEagles Were Built.” https://www.nfl.com/news/super-bowl-lii-how-the-2017-philadelphia-eagles-were-built-0ap3000000912753.\n\n\nSilge, Julia. n.d. “Tidymodels.” https://tidymodels.org.\n\n\nStikeleather, Jim. 2013. “The Three Elements of Successful Data\nVisualizations.” https://hbr.org/2013/04/the-three-elements-of-successf.\n\n\nWickham, Hadley. 2022. “Tidyverse Packages.” https://www.tidyverse.org/packages/."
  },
  {
    "objectID": "a1-nfl-analytics-dictionary.html#air-yards",
    "href": "a1-nfl-analytics-dictionary.html#air-yards",
    "title": "Appendix A — NFL Analytics Reference Guide",
    "section": "\nA.1 Air Yards",
    "text": "A.1 Air Yards\nAir yards is the measure that the ball travels through the air, from the line of scrimmage, to the exact point where the wide receivers catches, or does not catch, the football. It does not take into consideration the amount of yardage gained after the catch by the wide receiver (which would be yards after catch).\nFor an example, please see the below illustration. In it, the line of scrimmag is at the 20-yardline. The QB completes a pass that is caught at midfield (the 50-yardline). After catching the football, the wide receiver is able to advance the ball down to the opposing 30-yardline before getting tackled. First and foremost, the quarterback is credited with a total of 50 passing yards on the play, while the wide receiver is credited with the same.\nHowever, because air yards is a better metric to explore a QB’s true impact on a play, he is credited with 30 air yards while the wide receiver is credited with 20 yards after catch.\nIn the end, quarterbacks with higher air yards per attempt are generally assumed to be throwing the ball deeper downfield than QBs with lower air yards per attempt.\n\n\n\n\n\n\n\nThere are multiple ways to collect data pertaining to air yards. However, the most straightforward way is to use load_player_stats:\n\ndata <- nflreadr::load_player_stats(2021)\n\nair.yards <- data %>%\n  filter(season_type == \"REG\") %>%\n  group_by(player_id) %>%\n  summarize(\n    attempts = sum(attempts),\n    name = first(player_name),\n    air.yards = sum(passing_air_yards),\n    avg.ay = mean(passing_air_yards)) %>%\n  filter(attempts >= 100) %>%\n  select(name, air.yards, avg.ay) %>%\n  arrange(-air.yards)\n\ntibble(air.yards)\n\n# A tibble: 42 x 3\n   name       air.yards avg.ay\n   <chr>          <dbl>  <dbl>\n 1 T.Brady         5821   342.\n 2 J.Allen         5295   311.\n 3 M.Stafford      5094   300.\n 4 D.Carr          5084   299.\n 5 J.Herbert       5069   298.\n 6 P.Mahomes       4825   284.\n 7 T.Lawrence      4732   278.\n 8 D.Prescott      4612   288.\n 9 K.Cousins       4575   286.\n10 J.Burrow        4225   264.\n# ... with 32 more rows\n\n\nIn the above example, we can see that Tom Brady led the NFL during the 2021 regular season with a comined total of 5,821 air yards which works out to an average of 342 air yards per game."
  },
  {
    "objectID": "a1-nfl-analytics-dictionary.html#average-depth-of-target",
    "href": "a1-nfl-analytics-dictionary.html#average-depth-of-target",
    "title": "Appendix A — NFL Analytics Reference Guide",
    "section": "\nA.2 Average Depth of Target",
    "text": "A.2 Average Depth of Target\nAs mentioned above, a QB’s air yards per attempt can highlight whether or not he is attempting to push the ball deeper down field than his counterparts. The official name of this is Average Depth of Target (or ADOT). We can easily generate this statistic using the load_player_stats function within nflreader:\n\ndata <- nflreadr::load_player_stats(2021)\n\nadot <- data %>%\n  filter(season_type == \"REG\") %>%\n  group_by(player_id) %>%\n  summarize(\n    name = first(player_name),\n    attempts = sum(attempts),\n    air.yards = sum(passing_air_yards),\n    adot = air.yards / attempts) %>%\n  filter(attempts >= 100) %>%\n  arrange(-adot)\n\ntibble(adot)\n\n# A tibble: 42 x 5\n   player_id  name       attempts air.yards  adot\n   <chr>      <chr>         <int>     <dbl> <dbl>\n 1 00-0035704 D.Lock          111      1117 10.1 \n 2 00-0029263 R.Wilson        400      3955  9.89\n 3 00-0036945 J.Fields        270      2636  9.76\n 4 00-0034796 L.Jackson       382      3531  9.24\n 5 00-0036389 J.Hurts         432      3882  8.99\n 6 00-0034855 B.Mayfield      418      3651  8.73\n 7 00-0026498 M.Stafford      601      5094  8.48\n 8 00-0031503 J.Winston       161      1340  8.32\n 9 00-0034857 J.Allen         646      5295  8.20\n10 00-0029604 K.Cousins       561      4575  8.16\n# ... with 32 more rows\n\n\nAs seen in the results, if we ignore Drew Lock’s 10.1 ADOT on just 111 attempts during the 2021 regular season, Russell Wilson attempted to push the ball, on average, furtherst downfield among QBs with atleast 100 attempts."
  },
  {
    "objectID": "a2-nfl-further-reading.html#introduction-to-r-programming-books",
    "href": "a2-nfl-further-reading.html#introduction-to-r-programming-books",
    "title": "Appendix B — Further Reading Suggestions",
    "section": "B.1 Introduction to R Programming Books",
    "text": "B.1 Introduction to R Programming Books\n\nR for Data Science: Import, Tidy, Transform, Visualize, and Model Data\nHands-On Programming with R: Write Your Own Functions and Simulations\nThe Book of R: A First Course in Programming and Statistics\nLearning R: A Step-by-Step Function Guide to Data Analysis\nThe Art of R Programming: A Tour of Statistical Software Design\nAdvanced R (Second Edition)"
  },
  {
    "objectID": "a2-nfl-further-reading.html#data-visualization-in-r-and-visualization-guides",
    "href": "a2-nfl-further-reading.html#data-visualization-in-r-and-visualization-guides",
    "title": "Appendix B — Further Reading Suggestions",
    "section": "B.2 Data Visualization in R and Visualization Guides",
    "text": "B.2 Data Visualization in R and Visualization Guides\n\nR Graphics Cookbook: Practicl Recipes for Visualizing Data\nStorytelling with Data: A Data Visualization Guides for Business Professionals\nBetter Data Visualizations: A Guide for Scholars, Researchers, and Wonks"
  },
  {
    "objectID": "a2-nfl-further-reading.html#sport-analytics-guidesbooks",
    "href": "a2-nfl-further-reading.html#sport-analytics-guidesbooks",
    "title": "Appendix B — Further Reading Suggestions",
    "section": "B.3 Sport Analytics Guides/Books",
    "text": "B.3 Sport Analytics Guides/Books\n\nThe Midrange Theory: Basketball’s Evolution in the Age of Analytics\nAnalyzing Baseball Data with R (2nd edition)\nA Fan’s Guide to Baseball Analytics: Why WAR, WHIP, wOBA, and other Advanced Sabermetrics Are Essential to Understanding Modern Baseball\nThe Book: Playing the Percentages in Baseball\nThe Hidden Game of Baseball: A Revolutionary Approach to Baseball and Its Statistics\nThe Hidden Game of Football: A Revealing and Lively Look at the Pro Game, With New Stats, Revolutionary Strategies, and Keys to Picking the Winners\nMathletics: How Gamblers, Managers, and Fans Use Mathematics in Sports\nBasketball Data Science: With Applications in R\nData Analytics in Football (Soccer): Positional Data Collection, Modelling, and Analysis"
  }
]