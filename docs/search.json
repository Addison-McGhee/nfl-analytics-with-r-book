[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "An Introduction to NFL Analytics with R",
    "section": "",
    "text": "1 Introduction\nOn April 27, 2020, Ben Baldwin hit send on a Tweet that announced the birth of nflfastR, an R package designed to scrape NFL play-by-play data, allowing the end-user to access it at speeds quicker than similar predecessors (hence the name).\nThanks to the work of multiple people (@mrcaseB, @benbbaldwin, @TanHo, @LeeSharpeNFL, and @thomas_mock … to just name a few), the process of getting started with advanced analytics using NFL data is now easier than ever.\nThat said, and without getting too far into the weeds of the history behind it all, the above-mentioned people are responsible in some shape or form for the current status of the nflverse, which is a superb collection of data and R-based packages that allows anybody the ability to access deeply robust NFL data as far back as the 1999 season.\nThe nflverse as we know it today was initially birthed from the nflscrapR project, which was started by the Carnegie Mellon University student and profess duo of Maksim Horowitz and Sam Ventura. After Horowitz graduated - and got hired by the Atlanta Hawks - the nflscrapR package was taken over by fellow CMU student Ron Yorko (who would go on to receive his Ph.D. from the Statistics and Data Science program). The trio’s work on nflscrapR ultimately led to a peer-reviewed paper titled “nflWAR: A Reproducible Method for Offensive Player Evaluation in Football.” Ultimately, the nflscrapR project came to an end when the specific .json feed used to gather NFL data changed. At this point, Ben Baldwin and Sebastian Carl had already built upon the nflscrapR project’s foundations to create nflfastR. Ron officially marked the end of the nflscrapR era and the beginning of the nflfastR era with a tweet on September 14, 2020:1\nAs a reply to his first tweet about the nflfastR project, Ben explained that he created the original function to scrape NFL data for the creation of his NFL analytics website. Thankfully, he and Seb did not keep the creation to themselves and released nflfastR to the public. Because of the “open source” nature of R and R packages, a laundry list of companion packages quickly developed alongside nflfastR. The original nflfastR package is now part of the larger nflverse of packages that drive the NFL analytics community on Twitter and beyond.\nThe creation of the nflverse allowed for anybody interested in NFL analytics to easily access data, manipulate it to their liking, and release their visualizations and/or metrics to the wider public. In fact, it is now a regular occurrence for somebody to advance their R programming ability because of the nflverse and then go on to win the Big Data Bowl. As of the 2022 version of the Big Data Bowl, over “30 participants have been hired to work in data and analytics roles in sports, including 22 that were hired in football” (“Big Data Bowl: The Annual Analytics Contest Explores Statistical Innovations in Football,” n.d.). Most recently, the Chargers hired 2020 participate Alex Stern and the Chiefs hired Marc Richards, a member of the winning 2021 team, as a Football Research Analyst.\nKevin Clark, in a 2018 article for The Ringer, explained that despite not being as obvious as the sabermetrics movement in baseball, the analytics movement in the NFL is “happening in front of you all the time.” The use of analytics in the NFL did, however, predate Clark’s article. In 2014, Eagles head coach Doug Pederson explained that all decisions made by the organization - from game planning to draft strategy - were to be informed by hard data and analytics. Leading this early adoption of analytics, and reporting directly to team Vice President Howie Roseman, were Joe Douglas and Alec Halaby, “a 31-year-old Harvard grad with a job description” that had an emphasis on “integrating traditional and analytical methods in football decision-making.” The result? A “blending of old-school scouting and newer approaches” that were often only seen in other leagues, such as the NBA and MLB (Rosenthal 2018). Pederson believed in and trusted the team’s approach to analytics so much that a direct line of communication was created between the two during games, with the analytics department providing the head coach with math-based recommendations for any scenario Pederson requested (Awbrey 2020).2\nIn just under five years time since the publishing of that article, it has become hard to ignore the analytic movement within the NFL. Yet, there is still so much growth to happen in the marriage between the NFL and advanced metrics. For example, there is no denying that the sabermetrics movement drastically “altered baseball’s DNA” Heifetz (2019)]. Moreover, as explained in Seth Partnow’s outstanding The Midrange Theory: Basketball’s Evolution in the Age of Analytics, the analytics movement in the NBA essentially killed the midrange shot (briefly: it is more beneficial to try to work the ball in directly under the basket (for a high-percentage shot) or to take the 3-pointer, as the possible additional point is statistically worth more despite the lower success probability as opposed a 2-point midrange shot) as well as the traditional, “old-school” center position.\nCompared to both the NBA and MLB, the NFL is playing catch up in analytics driving changes equivalent to the death of the midrange shot or the plethora of additional tactics and changes to baseball because of sabermetrics. Joe Banner, who served as the President of the Eagles from 2001-2012 and then the Chief Executive Officer of the Browns from 2012-2013, explained that some of the hesitation to incorporate analytics into NFL game planning was a result of the game being “very much driven by conventional wisdom to an extreme degree” (Fortier 2020). Perhaps nobody encapsulates this better than Pittsburgh Steelers Head Coach Mike Tomlin. When asked about his position on analytics during the 2015 season, Tomlin explained:\nGiven that Tomlin’s quote is from 2015, perhaps the Steelers pivoted since and are now more analytically inclined. That does not seem to be the case. In a poll of NFL analytics staffers conducted by ESPN, the Steelers were voted as one of the least analytically advanced teams in the league.\nThere is large gap between the least analytically inclined teams (Washington, Tennessee, Cincinnati, New York Giants, and Pittsburgh) and those voted as the most analytically inclined (Baltimore, Cleveland, Philadelphia, and Houston). In the ESPN poll, the Browns were voted as the analytics department producing the highest level of work. One of those polled spoke to the fact that much of this outstanding work is a result of General Manager Andrew Berry being a “true believer,” explaining that he is one of the “rare guys you’ll come across in life where you think to yourself, ‘Man, this guy thinks at a different level. Just pure genius.’ He’s one of them.”\nIn his article for the Washington Post, Sam Fortier argues that many teams became inspired to more intimately introduce analytics into game planning and on-field decisions after the 2017 season. On their run to becoming Super Bowl Champions, the Philadelphia Eagles were aggressive on 4th down, going for it 26 times during the season and converting on 17 of those for a conversion percentage of 65.4%. A quick examination and visualization of data highlights the absolutely staggering increase in 4th aggressiveness among NFL head coaches from 2017-2021:\nThere has been a 96.3% increase in the number of 4th down attempts from just 2017 to 2021. In fact, the numbers may actually be higher as I was quite conservative in building the above plot by only considering those 4th down attempts that took place when the offensive team had between a 5-to-95% winning probability and those prior to the two-minute warning of either half. Even with those conservative limitations, the increase is staggering. The numbers, however, support this aggression. During week one of both the 2020 and 2021 season, not going for it on 4th down “cost teams a cumulative 170 percentage points of win probability” (Bushnell 2021).\nBen Baldwin, using the nfl4th package that is part of the nflverse, tracked the shift in NFL coaching mentality regarding 4th down decisions by comparing 2014’s “go for it percentage” against the same for 2020. When compared to the 2014 season, NFL coaches are now much more in agreement with analytics on when to “go for it” on 4th down in relation to the expected gain in win probability.\nIt should not be surprising then, considering Mike Tomlin’s quote from above and other NFL analytics staffers voting the Steelers as one of the least analytically driven teams in the league, that Pittsburgh lost the most win probability by either kicking or punting in “go for it” situations during the 2020 NFL season. On the other end, the Ravens and Browns - two teams voted as the most analytically inclined - are the two best organizations at knowing when to “go for it” on 4th down based on win probability added. There seems to be a defined relationship between teams buying into analytics and those who do not:\nThe NFL’s turn towards more aggressive 4th-down decisions is just one of the many analytics-driven changes occurring in the league. Another significant example is Defense-Adjusted Value over Average (or DVOA), a formula created by Aaron Schatz, now the editor in chief of Football Outsiders, that sought to challenge the notion that teams should, first, establish the running game in order to open up the passing game. Some of these changes are apparent on televisions screens on Sunday afternoons in the Fall, while others are occurring behind the scenes (analytics departments working on scouting and draft preparation, for example). Indeed, the use of analytics in the NFL is not as tightly ingrained as we see in other prominent leagues. And we must remember that there are certainly continued hold outs among some NFL coaches (like Mike Tomlin).\nDespite some coaching hold outs on fully embracing analytics, the “thirst for knowledge in football is as excessive as any other sport and the desire to get the most wins per dollar is just as high.” As the pipeline of data continues to grow, both internally in the league and data that becomes publicly accessible, “smart teams will continue to leave no rock unturned as they push the limits on how far data can take them.” Joe Banner explained that while the NFL has long been a league of coaches saying “well, that is the way we’ve always done it,” the league is ripe for a major shift (Bechtold 2021).\nBanner’s belief that those teams searching for every competitive advantage will “leave no rock unturned” is the driving force behind this book. For all intents and purposes, the age of analytics in the NFL is still in its infancy. Turning back, again, to the 2017 season, the Eagles’ management praised and credited the team’s analytics department as part of the reason they were able to win Super Bowl LII. Doing so Danney Heifetz argues, “changed the language of football.” The NFL, he explains, is a “copycat league” and, as witnessed with the increase in 4th down aggressiveness since 2017, teams immediately began to carbon copy Philadelphia’s approach to folding traditional football strategy with a new age analytics approach. Because of the modernity of this relationship between long-held football dogmas and analytics, nobody can be quite sure what other impacts it will create on the gamesmanship of football.\nHowever, as Heifetz opines, both the NBA and MLB can serve as a roadmap to where analytics will take the NFL. Importantly, the NFL’s relationship with analytics is still in its “first frontier of what will likely be a sweeping change over the next two decades.” Because of this, we cannot be sure what the next major impact analytics will make, nor when it may occur. But, with the ever-growing amount of publicly accessible data, it is only a matter of time until it is discovered. For example, in an interview with Heifetz, Brian Burke - one of the forefather’s of NFL analytics and now a writer for ESPN - expressed his belief that the next major impact will be “quantifying how often quarterbacks make the correct decision on the field.”\nIt seems that every new NFL season results in an amateur analyst bringing a groundbreaking model and/or approach to the table. Unlike, for example, MLB where there is little left to discover in terms of sabermetrics and new approaches to understanding the game and its associated strategy, the NFL is - for lack of a better phrase - an open playing field. With more and more data becoming available to the public, it is now easier than ever investigate your own ideas and suspicions and to create your own models to confirm your intuition.\nFor example, I am originally from the greater Pittsburgh area and am a big Steelers fan (which certainly explains some of the Steelers-centric examples I use in the writing of this book). I was adamant in my belief that Pittsburgh’s TJ Watt should win the 2021 Defensive Player of the Year award, despite many others calling for Los Angeles’ Aaron Donald to claim the title. In effort to prove my point, I sought out to design what I coined Adjusted Defensive Impact. To begin, I wanted to explore the idea that not all defensive sacks are created equal, as a player’s true impact is not always perfectly represented by top-level statistics.\nTo account for that, I opted to adjust and add statistical weight to sack statistics. This was done over multiple areas. For instance, not all players competed in all 17 regular-season games in 2021. To adjust for this, I took the total of game played in the data (2,936) and divided by 17 (a full season) to achieve a weighted adjustment of 0.0058. TJ Watt played in just 15 games in 2021. His adjusted equation, therefore, is (17-‘games’) * 0.0058. The result? He gets a bit more credit for this adjustment than, say, Myles Garrett who played all 17 regular-season games.\nGoing further with the model, I created a weighted adjustment for solo sacks (0.90), a negative weighted adjustment (-0.14) for any sack charted as “unblocked,” and a weighted adjustment to account for how many times a player actually rushed the QB compared to how many defensive snaps they played. Using data from the SIS Data Hub, the full code is below:\nThe end result? Taking into account the above adjusted defensive impact, TJ Watt was absolutely dominant during the 2021 season:\nAll of these examples - from Ben Baldwin’s 4th-down model, to Football Outsiders’ DVOA, to my attempt to further quantify defensive player impact - are just the leading edge of the burgeoning analytics movement in the NFL. Moreover, the beauty of analytics is that you do not have to be a mathematician or statistics buff in order to enter the fray. All it takes is a genuine curiosity to explore what Bob Carroll, Pete Palmer, and John Thorn coined as the “Hidden Game of Football” and the desire to learn, if you have not already, the R programming language."
  },
  {
    "objectID": "index.html#overview-of-chapters",
    "href": "index.html#overview-of-chapters",
    "title": "An Introduction to NFL Analytics with R",
    "section": "\n1.1 Overview of Chapters",
    "text": "1.1 Overview of Chapters\n\nChapter 1 provides an overview of the nflverse with specific attention paid to the difference between using nflfastR versus nflreadr. Serving as the first dive into analytics, the chapter showcases how to use nflreadr to retrieve both compiled weekly NFL stats and the deeply robust play-by-play statistics. In both cases, exercises are provided. Readers will do their first coding by, first, using the weekly stats to determine the 2021 leaders in air yards per attempt. Second, readers will use the play-by-play statistics from the 2021 season to create a brand new metric (QB aggressiveness on 3rd down pass attempts). Afterward, readers will learn how to retrieve multiple seasons of data at once.\nChapter 2 covers the process of downloading both R and RStudio, as well as the necessary packages to do NFL analytics. As one of the most important chapters in the book (especially for those new to the R programming language), readers take a deep dive into wrangling NFL data with the tidyverse package. To begin, readers will learn about the dplyr pipe (%>%) and use, in exercises, the six most important verbs in the dplyr language: filer(), select(), arrange(), summarize(), mutate(), and group_by(). At the conclusion of the chapter, multiple exercises are provided to allow readers to practice using the dplyr verbs, relational operators within the filter() function and creating “new stats” by using the summarize() function. Moreover, readers will determine the relationship between the dplyr language and important variables within the nflverse data such as player_name and player_id, which is important for correct manipulation and cleaning of data.\nChapter 3 examines the numerous and, often, bewildering amount of functions “underneath the hood” of the packages that makes up the nflverse. For example, load_pbp() and load_player_stats() are included in both nflfastR and nflreadr. However, load_nextgen_stats(), load_pfr_stats(), and load_contracts() are all part of just nflreadr. Because of this complexity, readers will learn how to efficiently operate within the nflverse. Moreover, chapter 3 provides dozens of examples and exercises related to all of the various functions included. For example, readers will learn to use load_nextgen_stats() to determine which running backs get to the line of scrimmage the quickest and will use load_pfr_stats() to explore advanced defensive metrics across multiple seasons.\nChapter 4 moves readers from data cleaning and manipulation to an introduction to data visualization using ggplot2. As well, chapter 4 provides further instruction on nflverse functions such as clean_player_names(), clean_team_abbrs(), and clean_homeaway(). As well, to prep for data visualization, readers will be introduced to the teams_colors_logos and load_rosters functions as well as the nflplotR package, which provides “functions and geoms to help visualization of NFL related analysis” (Carl 2022). Readers will produce multiple types of visualizations, including geom_bar, geom_point, geom_density, and more. As well, readers will learn to use facet_wrap and facet_grid to display data over multiple seasons. For visualizations that include team logos or player headshots, instruction will cover both how to do the coding manually using teams_colors_logos or load_rosters and to use the nflplotr package to avoid the need to use left_join to merge teams_colors_logos to your dataframe.\nChapter 5 introduces advanced methods in R using nflverse data, with a specific focus on modeling and machine learning. To streamline the process of learning, readers will be introduced to tidymodels, a “collection of packages for modeling and machine learning using tidyverse principles” (Silge, n.d.). As an example, readers will first be introduced to Tej Seth’s Rushing Yards Over Expected model (GitHub, ShinyApp). The model will serve as a learning tool to help readers understand the relationship between nflfastR data and machine learning (in Tej’s case, an xgboost model). Afterward, specific attention is given to binary classification, multiclass classification, and regression computer learning models. At the conclusion of the chapter, readers will be provided exercises to allow them to develop their own supervised and unsupervised machine learning models.\nChapter 6 introduces data from sources outside of the nflverse, including premium statistics from Pro Football Focus and Sports Info Solutions. Readers will learned to use various functions, such as clean_team_names, in order to prepare the data to merge with data from the nflverse. As well, this chapter will introduce readers to working with player tracking data. To do so, data will be provided from the NFL’s Big Data Bowl. To highlight the work being completed using player tracking, this chapter will discuss the Big Data Bowl entries of Matt Ploenzke (The Importance of Ball Carrier Downfield Acceleration and Unblocked Tackler Distance and Spacing) and the team of Kellin Rumsey & Brandon DeFlon (The Battle Between Blocker and Defender Is Often Decided by Leverage)."
  },
  {
    "objectID": "index.html#about-the-author",
    "href": "index.html#about-the-author",
    "title": "An Introduction to NFL Analytics with R",
    "section": "About The Author",
    "text": "About The Author\nI (Bradley Congelio) am currently an Assistant Professor in the College of Business at Kutztown University of Pennsylvania. Aside from my core area of instruction, I also instruct the very popular Sport Analytics (SPT 313) course.\nI earned my Ph.D. from the University of Western Ontario and received a specialized certificate in R for Data Analytics from the University of California, San Diego in 2021. I am a proud undergraduate alumni of West Liberty University and am a strong advocate of a broad-based liberal arts education.\nMy research focuses on using big data, the R programming language, and analytics to explore the impact of professional stadiums on neighboring communities. I use the proprietary Zillow ZTRAX database as well as U.S. Census and other forms of data to create robust, applied, and useful insight into how best to protect those living in areas where stadiums are proposed for construction.\nAs well, my work in sport analytics, specifically the NFL, has been featured on numerous media outlets, including the USA Today and Sports Illustrated.\nFinally, my most recent academic, peer-reviewed publications include:\n\nCongelio, B. (2022). ’Examining the Impact of New Stadium Construction on Local Property Prices Using Data Analytics and the Zillow ZTRAX Database.” Journal of Business, Economics, and Technology Spring 2022, 39-55.\nCongelio, B. (2021). “Monitoring the Policing of Olympic Host Cities: A Novel Approach Using Data Analytics and the LA2028 Olympic Summer Games.” Journal of Olympic Studies 2(2), 129-145.\nCongelio, B. “Predicting the Impact of a New Stadium on Surrounding Neighborhoods Through the Use of a k-means Unsupervised Clustering Algorithm.” Currently under peer review.\nCongelio, B. “Examining Megaevent’s Impact on Foot Traffic to Local Businesses Using Mobility and Demographic Aggregation Data.” Currently under peer review and funded by a $15,000 grant.\n\n\n1.1.1 Why A Book Instead of Working in Analytics?\nI am sometimes asked why I spend time in the classroom teaching this material rather than taking my domain knowledge to the “industry side” and working in the NFL or an otherwise NFL-connected outlet.\nThe honest and, likely boring, answer is this: I love teaching. My favorite experience in the classroom yet is always in my Sport Analytics course. The frustration and sense of helplessness is palpable in the first weeks of the semester as students attempt to wrap their head around, what a former student called, “this [censored] foreign language.” I insist that they keep pushing through the exercises and assignments. Often, there is line out my door and extending down the hallway during office hours comprised of just students from the Sport Analytics class.\nAnd then something amazing happens.\nTypically about halfway through the semester, I start seeing the light bulbs go off. Instead of cursing in anger at the “foreign language,” students begin randomly cursing in excitement as the flow of the tidyverse language “clicks.” Once that happens, it is off to the races because, once they understand speaking in tidyverse, learning more difficult packages (like tidymodels) seems doable.\nAnd that is why I teach. That moment where I realize my lecturing, assisting, explaining, and gentle nudging are all finally paying dividends - not for me, though. For the students.\nThis book serves as an extension of that classroom experience. As a reader of this book, you are now a “student” and I hope you do not hesitate to reach out to me if you ever have any questions or, more importantly, when (not if) you have that “light bulb moment” and everything begins to click for you."
  },
  {
    "objectID": "index.html#technical-details",
    "href": "index.html#technical-details",
    "title": "An Introduction to NFL Analytics with R",
    "section": "Technical Details",
    "text": "Technical Details\nThis book was written using RStudio’s Visual Editor for R Markdown. It was published using the Quarto publishing system built on Pandoc. As well, the following packages were used in this book:\n\n\n\n\nPackages Used In This Book\n \n package \n    version \n    source \n  \n\n\n dplyr \n    1.0.10 \n    CRAN (R 4.1.3) \n  \n\n ggplot2 \n    3.4.0 \n    CRAN (R 4.1.3) \n  \n\n gt \n    0.8.0 \n    CRAN (R 4.1.3) \n  \n\n nflfastR \n    4.4.0.9004 \n    https://nflverse.r-universe.dev (R 4.1.3) \n  \n\n nflreadr \n    1.3.1.07 \n    Github (nflverse/nflreadr\\@b77f17c1eb63f9df565c9560bbcb06c723e8c5c7) \n  \n\n nflverse \n    1.0.2 \n    https://nflverse.r-universe.dev (R 4.1.3) \n  \n\n scales \n    1.2.1 \n    CRAN (R 4.1.3) \n  \n\n tidymodels \n    1.0.0 \n    CRAN (R 4.1.3) \n  \n\n tidyverse \n    1.3.1 \n    CRAN (R 4.1.1) \n  \n\n webshot \n    0.5.2 \n    CRAN (R 4.1.1) \n  \n\n\n\n\nFinally, please note that this book uses the dplyr pipe operator (%>%) as opposed to the new, built-in pipe operator released with version 4.1 of R (|>). It is likely that you can work through the exercises and examples in this book by using either operator. I maintain my use of the dplyr pipe operator for no other reason than personal preference."
  },
  {
    "objectID": "index.html#license",
    "href": "index.html#license",
    "title": "An Introduction to NFL Analytics with R",
    "section": "\n1.2 License",
    "text": "1.2 License\nThe online version of this book is published with the Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0) license.\n\n\n\n\nAwbrey, Jake. 2020. “The Future of NFL Analytics.” https://www.samford.edu/sports-analytics/fans/2020/The-Future-of-NFL-Data-Analytics.\n\n\nBechtold, Taylor. 2021. “How the Analytics Movement Has Changed the NFL and Where It Has Fallen Short.” https://theanalyst.com/na/2021/04/evolution-of-the-analytics-movement-in-the-nfl/.\n\n\n“Big Data Bowl: The Annual Analytics Contest Explores Statistical Innovations in Football.” n.d. https://operations.nfl.com/gameday/analytics/big-data-bowl/.\n\n\nBushnell, Henry. 2021. “NFL Teams Are Taking 4th-down Risks More Than Ever - but Still Not Often Enough.” https://sports.yahoo.com/nfl-teams-are-taking-4th-down-risks-more-than-ever-but-still-not-often-enough-163650973.html.\n\n\nCarl, Sebastian. 2022. “nflplotR.” https://nflplotr.nflverse.com/.\n\n\nFortier, Sam. 2020. “The NFL’s Analytics Movement Has Finally Reached the Sport’s Mainstream.” https://www.washingtonpost.com/sports/2020/01/16/nfls-analytics-movement-has-finally-reached-sports-mainstream/.\n\n\nHeifetz, Danney. 2019. “We Salute You, Founding Father of the NFL’s Analytics Movement.” https://www.theringer.com/nfl-preview/2019/8/15/20806241/nfl-analytics-pro-football-focus.\n\n\nKozora, Alex. 2015. “Tomlin Prefers \"Feel over Analytics\".” http://steelersdepot.com/2015/09/tomlin-prefers-feel-over-analytics/.\n\n\nRosenthal, Gregg. 2018. “Super Bowl LII: How the 2017 Philadelphia Eagles Were Built.” https://www.nfl.com/news/super-bowl-lii-how-the-2017-philadelphia-eagles-were-built-0ap3000000912753.\n\n\nSilge, Julia. n.d. “Tidymodels.” https://tidymodels.org."
  },
  {
    "objectID": "01-nfl-analytics-and-r.html#introduction",
    "href": "01-nfl-analytics-and-r.html#introduction",
    "title": "\n2  An Introduction to NFL Analytics and the R Programming Language\n",
    "section": "\n2.1 Introduction",
    "text": "2.1 Introduction\nIt might seem odd to begin an introductory book with coding and visualization in Chapter 1, while placing information about learning the basics of the tidyverse in a later chapter. But there is good reason why I adopted this pedagogical approach in this book. As explained by Hadley Wickham and Garrett Grolemund in their outstanding book R for Data Science, the process of reading in and then cleaning data is not exactly the most exciting part of doing analytics. As evidence suggest, early excitement about and integration into a topic increases the likelihood of following up and learning the “boring” material.\nBecause of this, I follow the approach of Wickham and Grolemund and provide data that is already, for the most part, “tidied” and ready to be used. We will however, in later chapters, pull raw data directly from it source (such as nflreadr, Pro Football Reference, and Sports Info Solutions) that requires manipulation and cleaning before any significant analysis can begin.\n\n\n\n\n\n\nImportant\n\n\n\nI am assuming, while you may not have a full grasp of the tidyverse yet, that you do currently have base R and RStudio installed. If you do not, more detailed instructions are provided in Chapter 2. If you would rather jump right into this material, you can download base R and RStudio at the following links. Once both are installed, you can return to this point in the chapter to follow along.\nTo download/install base R: cran.rstudio.com\nTo download/install RStudio: RStudio Desktop (scroll to bottom of page for Mac options)\n\n\nMoreover, as briefly outlined in the Preface, we move through the process of learning NFL analytics via a close relationship with investigative inquiry. In this instance, we will define the process of investigative inquiry as one that seeks both knowledge and information about a problem/question through data-based research. To that end, we will routinely use the process throughout this book to uncover insights, patterns, and trends relating to both players and teams that serve to help us answer the problem/question we are examining.\nWhile it can - and should - be entertaining to develop visualization and models around arbitrarily picked statistics and metrics, it is important to remember that the end goal of the process is to glean useful insights that, ultimately, can be shared with the public. Much like the work done by a data analyst for a Fortune 500 company, the work you produce as a result of this book should do two things: (1.) provide deeper insight and knowledge about NFL teams and players and (2.) effectively communicate a story.\nThis is why the process of investigative inquiry is ingrained, as much as possible, into every example provided in this book. In doing so, the standard outline for completing an investigate inquiry is modified to fit the needs of this book - specifically, the addition of communicating your findings to the public at the end."
  },
  {
    "objectID": "01-nfl-analytics-and-r.html#the-investigate-inquiry-outline",
    "href": "01-nfl-analytics-and-r.html#the-investigate-inquiry-outline",
    "title": "\n2  An Introduction to NFL Analytics and the R Programming Language\n",
    "section": "\n2.2 The Investigate Inquiry Outline",
    "text": "2.2 The Investigate Inquiry Outline\n\nIdentify the problem or question. The first step in any investigative inquiry is to clearly define the problem or question that you are trying to answer. Many times, fans have questions about their individuals favorite team and/or players. For example, the 2022 Los Angeles Rams - the defending Super Bowl Champions - were eliminated from playoff contention with three weeks remaining in the season. With the early exit, the Rams tied the 1999 Denver Broncos for the earliest elimination from playoff contention for any prior Super Bowl Champion. The Rams’ early elimination can be explained by the high number of injuries during the season, including Matthew Stafford, Cooper Kupp, and Aaron Donald. Perhaps the biggest factor, though, was the inability to keep a healthy offensive line. In this specific example, in terms of identifying the problem or question, a potential problem or question to explore is: how many unique combinations of offensive linemen did the 2022 LA Rams use and where does it rank in NFL history? Have other teams in recent history faced the same amount of offensive line turnover yet still make the playoffs? As you can see, there are a number of different avenues in which the problem or question surrounding the Rams’ offensive line injury issues can be explored.\nGather data. With a question or problem determined, we now turn to the process of finding and gathering the necessary data to find answers. Unfortunately, data is not always going to be available to answer your investigate inquiry. For example, NFL’s tracking data is only released in partial form during the annual Big Data Bowl (explored later in Chapter ##). In the event that your question or problem requires data that is not available, you must loop back to Step 1 and reconfigure your question to match available data. In the case of the 2022 LA Rams’ offensive line, access to data that can answer the question is available through two cores avenues: the load_participation and load_snap_counts functions within the nflverse family of packages.\nClean and prepare the data. It is not often that the data you obtain to answer your question will be perfectly prepared to immediate analysis. As will be explored below, the data collected to explore the Rams’ offensive line combinations required both (1.) a critical thought process on how to best solve oddities in the data while still producing correct and reliable information (2.) the cleaning and preparation to make the changes as a result of that critical thinking process. As you progress through the many examples and exercises in this book, you will often be presented with prepared datasets that require you to determine the best approach to data manipulation through this critical thinking and cleaning/preparation process.\nAnalyze the data. After problem solving to ensure the data is as reliable and consistent as possible, we can turn to analyzing the data. In this case, since we are concerned with unique combinations of offensive linemen, we can quickly get results by using the n_distinct function within dplyr.\n\nVisualize the data. There are generally two options for visualizing data: plotting with ggplot or creating a table with gt and the outstanding companion package gtExtras. To that end, considering the following can help determine whether to present your findings in char or table format.\n\nThe type of data you are working with. If you have a large amount of numerical data that needs to be compared or analyzed, a table may be the most effective way to present this information. On the other hand, if you want to highlight trends or patterns in your data, a chart can help illustrate the information in a more clear manner.\nThe purpose of your visualization. You must consider what you ultimately want to communicate with your visualization. If you want to provide a detailed breakdown of your data, a table is usually more appropriate. However, if you want to show the overall trend or pattern in your data, a chart is going to be more effective.\nThe audience for your visualization. As you determine whether to use a chart or a table, think about who will be viewing your visualization and what level of detail they need. If your audience is familiar with the data and needs to see precise value, a table may be a better choice. If your audience is not as familiar with the data and you want to highlight the main trends or patterns, a chart my be more effective.\n\nBelow, we will explore visualizing our offensive linemen combinations in both chart and table format using multiple different variables for sake of comparison.\n\nInterpret and communicate the results. Lastly, it is time to communicate your results to the public. Whether this be through Twitter, a team blog, or a message board, there are numerous items to consider when preparing to build your story/narrative for sharing. This will be covered further in Chapter ## (Visualization) as well.\n\nWith a clear direction via the investigative inquiry process, we can turn to taking a deeper dive into the LA Rams’ 2022 offensive linemen issue."
  },
  {
    "objectID": "01-nfl-analytics-and-r.html#investigating-the-rams-2022-offensive-line",
    "href": "01-nfl-analytics-and-r.html#investigating-the-rams-2022-offensive-line",
    "title": "\n2  An Introduction to NFL Analytics and the R Programming Language\n",
    "section": "\n2.3 Investigating the Rams’ 2022 Offensive Line",
    "text": "2.3 Investigating the Rams’ 2022 Offensive Line\nThe “Super Bowl hangover” is real.\nAt least for the loser of the big game.\nSince the AFL and NFL merged in 1970, a total of 15 of the 51 losers of the Super Bowl went on to miss the playoffs in the following season, while 13 failed to even achieve a winning record. Teams coming off a Super Bowl victory have generally fared better, with the winners putting together a .500 record or better 45 out of 51 times.\nOf those six teams to not achieve a .500 record after winning the Super Bowl, only a few have been as downright terrible as the 2022 Los Angeles Rams.\nAs explained by Mike Ehrmann, the Rams’ poor Super Bowl defense is “what happens when a laundry list of things go wildly wrong at the same time” (Kirschner 2022). As outlined above in our investigative inquiry outline, one of the core items on the Rams’ laundry list of bad luck was the absurd amount of offensive linemen ending up on the injured list. This, combined with losing Andrew Whitworth to retirement after the Super Bowl, led to quarterback Matthew Stafford being sacked on 8.6-percent of his dropback attempts (a rate that nearly doubled from the previous season).\nGiven that context, just how historically bad was the Rams’ 2022 offensive line turnover? We can being diving into the data to find our results and build our story.\n\n2.3.1 Unique Offensive Line Combinations: How to Collect The Data?\nTo begin obtaining and preparing the data to determine the number of unique offensive line combinations the Rams had in the 2022 season, I turned to two possible options: the load_participation and load_snap_counts functions within the nflreadr package. The load_participation function will return, if include_pbp = TRUE a list of every player ID number that was on the field for each play, whereas load_snap_counts returns - on a per game basis - the percentage of snaps each player was on the field for.\nIn the end, using load_snap_counts created the most accurate, reliable, and straightforward way in each to collect unique offensive line combinations. The load_participation function resulted in several oddities in the data (not with the collection of it by the nflverse maintainers, but with individual NFL team strategies and formations). To highlight this, the following code will select the first offensive play for each team, in each game, up to week 15 of the 2022 season.\n\nparticipation <- nflreadr::load_participation(2022, include_pbp = TRUE)\nrosters <- nflreadr::load_rosters(2022) %>%\n  select(full_name, gsis_id, depth_chart_position)\n\noline_participation <- participation %>%\n  filter(play_type %in% c(\"pass\", \"run\")) %>%\n  group_by(nflverse_game_id, possession_team, fixed_drive) %>%\n  filter(fixed_drive == 1 | fixed_drive == 2) %>%\n  filter(row_number() == 1) %>%\n  select(nflverse_game_id, play_id, possession_team, \n         offense_personnel, offense_players) %>%\n  dplyr::mutate(gsis_id = stringr::str_split(offense_players, \";\")) %>%\n  tidyr::unnest(c(gsis_id)) %>%\n  left_join(rosters, by = c(\"gsis_id\" = \"gsis_id\"))\n\noline_participation <- oline_participation %>%\n  filter(depth_chart_position %in% c(\"T\", \"G\", \"C\")) %>%\n  group_by(nflverse_game_id, possession_team) %>%\n  mutate(starting_line = toString(full_name)) %>%\n  select(nflverse_game_id, possession_team, \n         offense_personnel, starting_line) %>%\n  distinct()\n\nWhile the output using the load_participation function is correct, a quick examination of the offense_personnel column causes concern about the viability of this approach to calculate the total number of unique offensive line combinations. A grouping and summing of the offense_personnel column highlights the issue.\n\noline_participation %>%\n  group_by(offense_personnel) %>%\n  summarize(total = n())\n\n# A tibble: 14 x 2\n   offense_personnel                        total\n   <chr>                                    <int>\n 1 1 RB, 0 TE, 4 WR                             3\n 2 1 RB, 1 TE, 3 WR                           193\n 3 1 RB, 2 TE, 2 WR                           130\n 4 1 RB, 3 TE, 1 WR                            14\n 5 2 QB, 1 RB, 1 TE, 2 WR                       2\n 6 2 RB, 0 TE, 3 WR                             1\n 7 2 RB, 1 TE, 2 WR                            73\n 8 2 RB, 2 TE, 1 WR                            10\n 9 3 RB, 1 TE, 1 WR                             1\n10 6 OL, 1 RB, 0 TE, 3 WR                       2\n11 6 OL, 1 RB, 1 TE, 2 WR                      11\n12 6 OL, 1 RB, 2 TE, 1 WR                       1\n13 6 OL, 2 RB, 0 TE, 2 WR                       1\n14 7 OL, 0 RB, 0 TE, 0 WR,1 P,1 LS,1 DL,1 K     1\n\n\nOf concern are rows 10 through 14. In 15 different cases, a team ran its first play of the game with six offensive linemen. And, in one case, the resulting data indicates that the Dallas Cowboys ran their first play in week 5 against the LA Rams with seven offensive linemen, one punter, one long snapper, and a kicker.\nIn the first case, the data is correct that the teams ran their first offensive play with six offensive linemen. For example, in its week 3 game against the Steelers, the data indicates the Cleveland Browns as having started Jack Conklin (tackle), Jedrick Wills Jr. (tackle), Joel Bitonio (guard), Michael Dunn (guard), Wyatt Teller (guard), and Ethan Pocic (center). A view of the NFL’s All-22 film confirms that, indeed, all six offensive linemen were on the field for the Browns’ first snap of the game.\n\n\nSteelers vs. Browns: 6 Offensive Linemen\n\n\nIn the second case, Dallas’ offense personnel on its “first play” from scrimmage is the result of the Cowboys returning a fumble for a touchdown on the Rams’ first offensive possession with a botched snap on the ensuing extra point attempt. Because of that, the extra point attempt is no longer scored as an extra_point in the play_type variable within the play-by-play data, but a rushing attempt. As a result of this oddity, the data is correct in listing Dallas’ first offensive play as coming out of an extra point personnel grouping.\nBoth of these examples are problematic as a team’s “starting offensive line” is considered to be just five players: the left tackle, the left guard, the center, the right guard, and the right tackle. In order to correctly determine the number of combinations used, we need to first determine the five most-commonly used offensive linemen for each team. Because of the off-the-wall situations that can occur in football, building offensive line combinations through personnel groupings in the play-by–play data is tricky, at best.\nBecause of this, we can turn to the load_snap_counts function with the nflreadr package to determine the number of unique offensive line combinations. The process to do so occurs over several steps and involves decision-making on our end on how best to accurately represent the five core offensive linemen for each team.\n\noline_snap_counts <- nflreadr::load_snap_counts(seasons = 2022)\n\noline_snap_counts <- oline_snap_counts %>%\n  select(game_id, week, player, position, team, offense_pct) %>%\n  filter(position %in% c(\"T\", \"G\", \"C\")) %>%\n  group_by(game_id, team) %>%\n  arrange(-offense_pct) %>%\n  slice(1:5) %>%\n  ungroup()\n\nFirst, we obtain snap count data from the 2022 season and write it into a dateframe titled oline_snap_counts. After, we select just the necessary columns and then filter out the position information to include only tackles, guards, and centers. After grouping each individual offensive line by game_id and its respective team, we arrange each player’s snap count in descending order using offense_pct.\nAnd this is where a decision needs to be made on how to best construct the five starting offensive linemen for each team. By including slice(1:5), we are essentially selecting just the five offensive linemen with the most snap counts in that singular game.\nAre these five plays necessarily the same five that started the game as the two tackles, two guards, and one center? Perhaps not. But, hypothetically, a team’s starting center could have been injured a series or two in the game and the second-string center played the bulk of the snaps in that game.\nBecause of such situations, we can make the argument that the five offensive line players with the highest percentage of snap counts for each unique game_id are to be considered the combination of players used in that game.\nNext, let’s make the decision to arrange each team’s offensive line, by game, in alphabetical order. Since we do not have a reliable way to include specific offensive line positions (that is, we have tackle instead of left tackle or right tackle), we can build our combination numbers strictly based on the five downed linemen, regardless of specific position on the line of scrimmage.\nAfter, we use the toString function to place all five names into a single column (starting_line) and then filter out the data to include just one game_id for the linemen.\n\noline_snap_counts <- oline_snap_counts %>%\n  group_by(game_id, team) %>%\n  arrange(player, .by_group = TRUE)\n\noline_final_data <- oline_snap_counts %>%\n  group_by(game_id, week, team) %>%\n  mutate(starting_line = toString(player)) %>%\n  select(game_id, week, team, starting_line) %>%\n  distinct(game_id, .keep_all = TRUE)\n\nThe end result includes the game_id, the week, the team abbreviation, and the starting_line column that includes the names of the five offensive line players with the highest snap count percentage for that specific game.\n\n\n# A tibble: 6 x 4\n# Groups:   game_id, week, team [6]\n  game_id          week team  starting_line                                     \n  <chr>           <int> <chr> <chr>                                             \n1 2022_01_BAL_NYJ     1 BAL   Ben Powers, Kevin Zeitler, Morgan Moses, Patrick ~\n2 2022_01_BAL_NYJ     1 NYJ   Alijah Vera-Tucker, Connor McGovern, George Fant,~\n3 2022_01_BUF_LA      1 BUF   Dion Dawkins, Mitch Morse, Rodger Saffold, Ryan B~\n4 2022_01_BUF_LA      1 LA    Brian Allen, Coleman Shelton, David Edwards, Jose~\n5 2022_01_CLE_CAR     1 CAR   Austin Corbett, Brady Christensen, Ikem Ekwonu, P~\n6 2022_01_CLE_CAR     1 CLE   Ethan Pocic, James Hudson, Jedrick Wills Jr., Joe~\n\n\n\n\n\n\n\nKirschner, Alex. 2022. “The Rams’ Super Bowl Afterparty Turned into a Historic Hangover.” https://fivethirtyeight.com/features/the-rams-super-bowl-afterparty-turned-into-a-historic-hangover/."
  },
  {
    "objectID": "02-nfl-analytics-tidyverse.html#downloading-r-and-rstudio",
    "href": "02-nfl-analytics-tidyverse.html#downloading-r-and-rstudio",
    "title": "3  Wrangling NFL Data in the tidyverse",
    "section": "3.1 Downloading R and RStudio",
    "text": "3.1 Downloading R and RStudio"
  },
  {
    "objectID": "02-nfl-analytics-tidyverse.html#installing-necessary-packages",
    "href": "02-nfl-analytics-tidyverse.html#installing-necessary-packages",
    "title": "3  Wrangling NFL Data in the tidyverse",
    "section": "3.2 Installing Necessary Packages",
    "text": "3.2 Installing Necessary Packages"
  },
  {
    "objectID": "02-nfl-analytics-tidyverse.html#the-tidyverse-language",
    "href": "02-nfl-analytics-tidyverse.html#the-tidyverse-language",
    "title": "3  Wrangling NFL Data in the tidyverse",
    "section": "3.3 The tidyverse Language",
    "text": "3.3 The tidyverse Language"
  },
  {
    "objectID": "04-nfl-analytics-visualization.html#data-viz-must-understand-the-audience",
    "href": "04-nfl-analytics-visualization.html#data-viz-must-understand-the-audience",
    "title": "\n5  Data Visualization with NFL Analytics\n",
    "section": "\n5.1 Data Viz Must Understand the Audience",
    "text": "5.1 Data Viz Must Understand the Audience\nAs explained by Stikeleather, the core purpose of a data visualization is to take “great quantities of information” and then convey that information in such a way that it is “easily assimilated by the consumers of the information.” In other words, the process of data visualization should allow for a great quantity of data to be distilled into an easily consumable (and understandable!) format.\nSpeaking specifically to NFL analytics, when doing visualizations we must be conscious about whether or not the intended audience will understand the terminology and concepts we use in the plot. For example, most all NFL fans understand the “non-advanced” statistics in the sport. But, when plots start using metrics such as EPA or completion percentage over expected, for example, the audience looking at the plot may very well have little understanding of what is being conveyed.\nBecause of this, any data viz I create never fails to include “directables” within the plot. These “directables” may be arrows that indicate which trend on the plot are “good” or they can be text within a scatterplot that explains what each quadrant means. Or, for example, I sometimes include a textual explanation of the “equation” used to develop a metric as seen below:\n\n\n\n\n\nThe above plot explores which QBs, from the 2020 season, were most aggressive on 3rd down with between 5 to 10 yards to go. Since “aggressiveness” is not a typical, day-to-day metric discussed by NFL fans, I included a “directable” within the subtitle of the plot that explained that the plot, first, was examining just 3rd down pass attempts within a specific yard range. And, second, I made the decision to include how “aggressiveness” was calculated by including the simple equation within the subtitle as well. Doing so allows even the most casual of NFL fans to easily understand what the plot is showing - in this case, that Joe Burrow’s 3rd down pass attempts with between 5 to 10 yards to go made it to the line of gain, or more, on 68% of his attempts. On the other hand, Drew Lock and Drew Brees were the least aggressive QBs in the line based on the same metric.\nAs another example, below is what I deemed my “Uncle Rico Metric” (because who does not like a good Napoleon Dynamite reference?):"
  },
  {
    "objectID": "04-nfl-analytics-visualization.html#setting-up-for-data-viz",
    "href": "04-nfl-analytics-visualization.html#setting-up-for-data-viz",
    "title": "\n5  Data Visualization with NFL Analytics\n",
    "section": "\n5.2 Setting Up for Data Viz",
    "text": "5.2 Setting Up for Data Viz\nWhile most of your journey through NFL analytics in this book required you to use the tidyverse and a handful of other packages, the process of creating compelling and meaningful data visualizations will require you to utilize multitudes of other packages. Of course, the most important is ggplot2 which is already installed via the tidyverse. However, in order to recreate the visualizations included in this chapter, it is required that you install other R packages. To install the necessary packages, you can run the following code in RStudio:"
  },
  {
    "objectID": "04-nfl-analytics-visualization.html#selecting-the-correct-type-of-plot",
    "href": "04-nfl-analytics-visualization.html#selecting-the-correct-type-of-plot",
    "title": "\n5  Data Visualization with NFL Analytics\n",
    "section": "\n5.3 Selecting The Correct Type of Plot",
    "text": "5.3 Selecting The Correct Type of Plot\n\n\n\n\nStikeleather, Jim. 2013. “The Three Elements of Successful Data Visualizations.” https://hbr.org/2013/04/the-three-elements-of-successf."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Awbrey, Jake. 2020. “The Future of NFL Analytics.” https://www.samford.edu/sports-analytics/fans/2020/The-Future-of-NFL-Data-Analytics.\n\n\nBechtold, Taylor. 2021. “How the Analytics Movement Has Changed\nthe NFL and Where It Has Fallen Short.” https://theanalyst.com/na/2021/04/evolution-of-the-analytics-movement-in-the-nfl/.\n\n\n“Big Data Bowl: The Annual Analytics Contest Explores Statistical\nInnovations in Football.” n.d. https://operations.nfl.com/gameday/analytics/big-data-bowl/.\n\n\nBushnell, Henry. 2021. “NFL Teams Are Taking 4th-down Risks More\nThan Ever - but Still Not Often Enough.” https://sports.yahoo.com/nfl-teams-are-taking-4th-down-risks-more-than-ever-but-still-not-often-enough-163650973.html.\n\n\nCarl, Sebastian. 2022. “nflplotR.” https://nflplotr.nflverse.com/.\n\n\nFortier, Sam. 2020. “The NFL’s Analytics Movement Has Finally\nReached the Sport’s Mainstream.” https://www.washingtonpost.com/sports/2020/01/16/nfls-analytics-movement-has-finally-reached-sports-mainstream/.\n\n\nHeifetz, Danney. 2019. “We Salute You, Founding Father of the\nNFL’s Analytics Movement.” https://www.theringer.com/nfl-preview/2019/8/15/20806241/nfl-analytics-pro-football-focus.\n\n\nKirschner, Alex. 2022. “The Rams’ Super Bowl Afterparty Turned\ninto a Historic Hangover.” https://fivethirtyeight.com/features/the-rams-super-bowl-afterparty-turned-into-a-historic-hangover/.\n\n\nKozora, Alex. 2015. “Tomlin Prefers \"Feel over Analytics\".”\nhttp://steelersdepot.com/2015/09/tomlin-prefers-feel-over-analytics/.\n\n\nRosenthal, Gregg. 2018. “Super Bowl LII: How the 2017 Philadelphia\nEagles Were Built.” https://www.nfl.com/news/super-bowl-lii-how-the-2017-philadelphia-eagles-were-built-0ap3000000912753.\n\n\nSilge, Julia. n.d. “Tidymodels.” https://tidymodels.org.\n\n\nStikeleather, Jim. 2013. “The Three Elements of Successful Data\nVisualizations.” https://hbr.org/2013/04/the-three-elements-of-successf."
  },
  {
    "objectID": "a1-nfl-analytics-dictionary.html#air-yards",
    "href": "a1-nfl-analytics-dictionary.html#air-yards",
    "title": "Appendix A — NFL Analytics Reference Guide",
    "section": "\nA.1 Air Yards",
    "text": "A.1 Air Yards\nAir yards is the measure that the ball travels through the air, from the line of scrimmage, to the exact point where the wide receivers catches, or does not catch, the football. It does not take into consideration the amount of yardage gained after the catch by the wide receiver (which would be yards after catch).\nFor an example, please see the below illustration. In it, the line of scrimmag is at the 20-yardline. The QB completes a pass that is caught at midfield (the 50-yardline). After catching the football, the wide receiver is able to advance the ball down to the opposing 30-yardline before getting tackled. First and foremost, the quarterback is credited with a total of 50 passing yards on the play, while the wide receiver is credited with the same.\nHowever, because air yards is a better metric to explore a QB’s true impact on a play, he is credited with 30 air yards while the wide receiver is credited with 20 yards after catch.\nIn the end, quarterbacks with higher air yards per attempt are generally assumed to be throwing the ball deeper downfield than QBs with lower air yards per attempt.\n\n\n\n\n\n\n\nThere are multiple ways to collect data pertaining to air yards. However, the most straightforward way is to use load_player_stats:\n\ndata <- nflreadr::load_player_stats(2021)\n\nair.yards <- data %>%\n  filter(season_type == \"REG\") %>%\n  group_by(player_id) %>%\n  summarize(\n    attempts = sum(attempts),\n    name = first(player_name),\n    air.yards = sum(passing_air_yards),\n    avg.ay = mean(passing_air_yards)) %>%\n  filter(attempts >= 100) %>%\n  select(name, air.yards, avg.ay) %>%\n  arrange(-air.yards)\n\ntibble(air.yards)\n\n# A tibble: 42 x 3\n   name       air.yards avg.ay\n   <chr>          <dbl>  <dbl>\n 1 T.Brady         5821   342.\n 2 J.Allen         5295   311.\n 3 M.Stafford      5094   300.\n 4 D.Carr          5084   299.\n 5 J.Herbert       5069   298.\n 6 P.Mahomes       4825   284.\n 7 T.Lawrence      4732   278.\n 8 D.Prescott      4612   288.\n 9 K.Cousins       4575   286.\n10 J.Burrow        4225   264.\n# ... with 32 more rows\n\n\nIn the above example, we can see that Tom Brady led the NFL during the 2021 regular season with a comined total of 5,821 air yards which works out to an average of 342 air yards per game."
  },
  {
    "objectID": "a1-nfl-analytics-dictionary.html#average-depth-of-target",
    "href": "a1-nfl-analytics-dictionary.html#average-depth-of-target",
    "title": "Appendix A — NFL Analytics Reference Guide",
    "section": "\nA.2 Average Depth of Target",
    "text": "A.2 Average Depth of Target\nAs mentioned above, a QB’s air yards per attempt can highlight whether or not he is attempting to push the ball deeper down field than his counterparts. The official name of this is Average Depth of Target (or ADOT). We can easily generate this statistic using the load_player_stats function within nflreader:\n\ndata <- nflreadr::load_player_stats(2021)\n\nadot <- data %>%\n  filter(season_type == \"REG\") %>%\n  group_by(player_id) %>%\n  summarize(\n    name = first(player_name),\n    attempts = sum(attempts),\n    air.yards = sum(passing_air_yards),\n    adot = air.yards / attempts) %>%\n  filter(attempts >= 100) %>%\n  arrange(-adot)\n\ntibble(adot)\n\n# A tibble: 42 x 5\n   player_id  name       attempts air.yards  adot\n   <chr>      <chr>         <int>     <dbl> <dbl>\n 1 00-0035704 D.Lock          111      1117 10.1 \n 2 00-0029263 R.Wilson        400      3955  9.89\n 3 00-0036945 J.Fields        270      2636  9.76\n 4 00-0034796 L.Jackson       382      3531  9.24\n 5 00-0036389 J.Hurts         432      3882  8.99\n 6 00-0034855 B.Mayfield      418      3651  8.73\n 7 00-0026498 M.Stafford      601      5094  8.48\n 8 00-0031503 J.Winston       161      1340  8.32\n 9 00-0034857 J.Allen         646      5295  8.20\n10 00-0029604 K.Cousins       561      4575  8.16\n# ... with 32 more rows\n\n\nAs seen in the results, if we ignore Drew Lock’s 10.1 ADOT on just 111 attempts during the 2021 regular season, Russell Wilson attempted to push the ball, on average, furtherst downfield among QBs with atleast 100 attempts."
  },
  {
    "objectID": "a2-nfl-further-reading.html#introduction-to-r-programming-books",
    "href": "a2-nfl-further-reading.html#introduction-to-r-programming-books",
    "title": "Appendix B — Further Reading Suggestions",
    "section": "B.1 Introduction to R Programming Books",
    "text": "B.1 Introduction to R Programming Books\n\nR for Data Science: Import, Tidy, Transform, Visualize, and Model Data\nHands-On Programming with R: Write Your Own Functions and Simulations\nThe Book of R: A First Course in Programming and Statistics\nLearning R: A Step-by-Step Function Guide to Data Analysis\nThe Art of R Programming: A Tour of Statistical Software Design\nAdvanced R (Second Edition)"
  },
  {
    "objectID": "a2-nfl-further-reading.html#data-visualization-in-r-and-visualization-guides",
    "href": "a2-nfl-further-reading.html#data-visualization-in-r-and-visualization-guides",
    "title": "Appendix B — Further Reading Suggestions",
    "section": "B.2 Data Visualization in R and Visualization Guides",
    "text": "B.2 Data Visualization in R and Visualization Guides\n\nR Graphics Cookbook: Practicl Recipes for Visualizing Data\nStorytelling with Data: A Data Visualization Guides for Business Professionals\nBetter Data Visualizations: A Guide for Scholars, Researchers, and Wonks"
  },
  {
    "objectID": "a2-nfl-further-reading.html#sport-analytics-guidesbooks",
    "href": "a2-nfl-further-reading.html#sport-analytics-guidesbooks",
    "title": "Appendix B — Further Reading Suggestions",
    "section": "B.3 Sport Analytics Guides/Books",
    "text": "B.3 Sport Analytics Guides/Books\n\nThe Midrange Theory: Basketball’s Evolution in the Age of Analytics\nAnalyzing Baseball Data with R (2nd edition)\nA Fan’s Guide to Baseball Analytics: Why WAR, WHIP, wOBA, and other Advanced Sabermetrics Are Essential to Understanding Modern Baseball\nThe Book: Playing the Percentages in Baseball\nThe Hidden Game of Baseball: A Revolutionary Approach to Baseball and Its Statistics\nThe Hidden Game of Football: A Revealing and Lively Look at the Pro Game, With New Stats, Revolutionary Strategies, and Keys to Picking the Winners\nMathletics: How Gamblers, Managers, and Fans Use Mathematics in Sports\nBasketball Data Science: With Applications in R\nData Analytics in Football (Soccer): Positional Data Collection, Modelling, and Analysis"
  }
]